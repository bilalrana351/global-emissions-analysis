{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "715d5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (50191, 79)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "      <th>cement_co2</th>\n",
       "      <th>cement_co2_per_capita</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>...</th>\n",
       "      <th>share_global_other_co2</th>\n",
       "      <th>share_of_temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_ch4</th>\n",
       "      <th>temperature_change_from_co2</th>\n",
       "      <th>temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_n2o</th>\n",
       "      <th>total_ghg</th>\n",
       "      <th>total_ghg_excluding_lucf</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1750</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2802560.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1751</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1752</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1753</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1754</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1755</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1756</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1757</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1758</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1759</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1760</td>\n",
       "      <td>AFG</td>\n",
       "      <td>2866255.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1761</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1762</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1763</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1764</td>\n",
       "      <td>AFG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  year iso_code  population  gdp  cement_co2  \\\n",
       "0   Afghanistan  1750      AFG   2802560.0  NaN         0.0   \n",
       "1   Afghanistan  1751      AFG         NaN  NaN         0.0   \n",
       "2   Afghanistan  1752      AFG         NaN  NaN         0.0   \n",
       "3   Afghanistan  1753      AFG         NaN  NaN         0.0   \n",
       "4   Afghanistan  1754      AFG         NaN  NaN         0.0   \n",
       "5   Afghanistan  1755      AFG         NaN  NaN         0.0   \n",
       "6   Afghanistan  1756      AFG         NaN  NaN         0.0   \n",
       "7   Afghanistan  1757      AFG         NaN  NaN         0.0   \n",
       "8   Afghanistan  1758      AFG         NaN  NaN         0.0   \n",
       "9   Afghanistan  1759      AFG         NaN  NaN         0.0   \n",
       "10  Afghanistan  1760      AFG   2866255.0  NaN         0.0   \n",
       "11  Afghanistan  1761      AFG         NaN  NaN         0.0   \n",
       "12  Afghanistan  1762      AFG         NaN  NaN         0.0   \n",
       "13  Afghanistan  1763      AFG         NaN  NaN         0.0   \n",
       "14  Afghanistan  1764      AFG         NaN  NaN         0.0   \n",
       "\n",
       "    cement_co2_per_capita  co2  co2_growth_abs  co2_growth_prct  ...  \\\n",
       "0                     0.0  NaN             NaN              NaN  ...   \n",
       "1                     NaN  NaN             NaN              NaN  ...   \n",
       "2                     NaN  NaN             NaN              NaN  ...   \n",
       "3                     NaN  NaN             NaN              NaN  ...   \n",
       "4                     NaN  NaN             NaN              NaN  ...   \n",
       "5                     NaN  NaN             NaN              NaN  ...   \n",
       "6                     NaN  NaN             NaN              NaN  ...   \n",
       "7                     NaN  NaN             NaN              NaN  ...   \n",
       "8                     NaN  NaN             NaN              NaN  ...   \n",
       "9                     NaN  NaN             NaN              NaN  ...   \n",
       "10                    0.0  NaN             NaN              NaN  ...   \n",
       "11                    NaN  NaN             NaN              NaN  ...   \n",
       "12                    NaN  NaN             NaN              NaN  ...   \n",
       "13                    NaN  NaN             NaN              NaN  ...   \n",
       "14                    NaN  NaN             NaN              NaN  ...   \n",
       "\n",
       "    share_global_other_co2  share_of_temperature_change_from_ghg  \\\n",
       "0                      NaN                                   NaN   \n",
       "1                      NaN                                   NaN   \n",
       "2                      NaN                                   NaN   \n",
       "3                      NaN                                   NaN   \n",
       "4                      NaN                                   NaN   \n",
       "5                      NaN                                   NaN   \n",
       "6                      NaN                                   NaN   \n",
       "7                      NaN                                   NaN   \n",
       "8                      NaN                                   NaN   \n",
       "9                      NaN                                   NaN   \n",
       "10                     NaN                                   NaN   \n",
       "11                     NaN                                   NaN   \n",
       "12                     NaN                                   NaN   \n",
       "13                     NaN                                   NaN   \n",
       "14                     NaN                                   NaN   \n",
       "\n",
       "    temperature_change_from_ch4  temperature_change_from_co2  \\\n",
       "0                           NaN                          NaN   \n",
       "1                           NaN                          NaN   \n",
       "2                           NaN                          NaN   \n",
       "3                           NaN                          NaN   \n",
       "4                           NaN                          NaN   \n",
       "5                           NaN                          NaN   \n",
       "6                           NaN                          NaN   \n",
       "7                           NaN                          NaN   \n",
       "8                           NaN                          NaN   \n",
       "9                           NaN                          NaN   \n",
       "10                          NaN                          NaN   \n",
       "11                          NaN                          NaN   \n",
       "12                          NaN                          NaN   \n",
       "13                          NaN                          NaN   \n",
       "14                          NaN                          NaN   \n",
       "\n",
       "    temperature_change_from_ghg  temperature_change_from_n2o  total_ghg  \\\n",
       "0                           NaN                          NaN        NaN   \n",
       "1                           NaN                          NaN        NaN   \n",
       "2                           NaN                          NaN        NaN   \n",
       "3                           NaN                          NaN        NaN   \n",
       "4                           NaN                          NaN        NaN   \n",
       "5                           NaN                          NaN        NaN   \n",
       "6                           NaN                          NaN        NaN   \n",
       "7                           NaN                          NaN        NaN   \n",
       "8                           NaN                          NaN        NaN   \n",
       "9                           NaN                          NaN        NaN   \n",
       "10                          NaN                          NaN        NaN   \n",
       "11                          NaN                          NaN        NaN   \n",
       "12                          NaN                          NaN        NaN   \n",
       "13                          NaN                          NaN        NaN   \n",
       "14                          NaN                          NaN        NaN   \n",
       "\n",
       "    total_ghg_excluding_lucf  trade_co2  trade_co2_share  \n",
       "0                        NaN        NaN              NaN  \n",
       "1                        NaN        NaN              NaN  \n",
       "2                        NaN        NaN              NaN  \n",
       "3                        NaN        NaN              NaN  \n",
       "4                        NaN        NaN              NaN  \n",
       "5                        NaN        NaN              NaN  \n",
       "6                        NaN        NaN              NaN  \n",
       "7                        NaN        NaN              NaN  \n",
       "8                        NaN        NaN              NaN  \n",
       "9                        NaN        NaN              NaN  \n",
       "10                       NaN        NaN              NaN  \n",
       "11                       NaN        NaN              NaN  \n",
       "12                       NaN        NaN              NaN  \n",
       "13                       NaN        NaN              NaN  \n",
       "14                       NaN        NaN              NaN  \n",
       "\n",
       "[15 rows x 79 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('owid-co2-data.csv')\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02322a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of missing values per column:\n",
      "\n",
      "                                   Column  Missing Values\n",
      "                                  country               0\n",
      "                                     year               0\n",
      "                                 iso_code            7929\n",
      "                               population            9172\n",
      "                                      gdp           34940\n",
      "                               cement_co2           21328\n",
      "                    cement_co2_per_capita           24833\n",
      "                                      co2           21054\n",
      "                           co2_growth_abs           23210\n",
      "                          co2_growth_prct           24189\n",
      "                        co2_including_luc           26606\n",
      "             co2_including_luc_growth_abs           26906\n",
      "            co2_including_luc_growth_prct           26906\n",
      "             co2_including_luc_per_capita           26696\n",
      "                co2_including_luc_per_gdp           33401\n",
      "        co2_including_luc_per_unit_energy           40490\n",
      "                           co2_per_capita           24009\n",
      "                              co2_per_gdp           32663\n",
      "                      co2_per_unit_energy           39841\n",
      "                                 coal_co2           28436\n",
      "                      coal_co2_per_capita           29141\n",
      "                          consumption_co2           45325\n",
      "               consumption_co2_per_capita           45689\n",
      "                  consumption_co2_per_gdp           45747\n",
      "                    cumulative_cement_co2           21350\n",
      "                           cumulative_co2           22863\n",
      "             cumulative_co2_including_luc           26606\n",
      "                      cumulative_coal_co2           28436\n",
      "                   cumulative_flaring_co2           34300\n",
      "                       cumulative_gas_co2           32177\n",
      "                       cumulative_luc_co2           12955\n",
      "                       cumulative_oil_co2           24974\n",
      "                     cumulative_other_co2           46989\n",
      "                        energy_per_capita           40082\n",
      "                           energy_per_gdp           42495\n",
      "                              flaring_co2           34239\n",
      "                   flaring_co2_per_capita           35497\n",
      "                                  gas_co2           32177\n",
      "                       gas_co2_per_capita           32899\n",
      "            ghg_excluding_lucf_per_capita           14552\n",
      "                           ghg_per_capita           14378\n",
      "                      land_use_change_co2           12955\n",
      "           land_use_change_co2_per_capita           13757\n",
      "                                  methane           12781\n",
      "                       methane_per_capita           14378\n",
      "                            nitrous_oxide           11911\n",
      "                 nitrous_oxide_per_capita           13871\n",
      "                                  oil_co2           24973\n",
      "                       oil_co2_per_capita           25755\n",
      "                     other_co2_per_capita           47717\n",
      "                       other_industry_co2           46989\n",
      "               primary_energy_consumption           40040\n",
      "                  share_global_cement_co2           28231\n",
      "                         share_global_co2           22863\n",
      "           share_global_co2_including_luc           26606\n",
      "                    share_global_coal_co2           28436\n",
      "       share_global_cumulative_cement_co2           28231\n",
      "              share_global_cumulative_co2           22863\n",
      "share_global_cumulative_co2_including_luc           26606\n",
      "         share_global_cumulative_coal_co2           28436\n",
      "      share_global_cumulative_flaring_co2           39322\n",
      "          share_global_cumulative_gas_co2           35157\n",
      "          share_global_cumulative_luc_co2           12955\n",
      "          share_global_cumulative_oil_co2           26599\n",
      "        share_global_cumulative_other_co2           48083\n",
      "                 share_global_flaring_co2           39322\n",
      "                     share_global_gas_co2           35157\n",
      "                     share_global_luc_co2           12955\n",
      "                     share_global_oil_co2           26599\n",
      "                   share_global_other_co2           48083\n",
      "     share_of_temperature_change_from_ghg            9190\n",
      "              temperature_change_from_ch4           12131\n",
      "              temperature_change_from_co2            9190\n",
      "              temperature_change_from_ghg            9190\n",
      "              temperature_change_from_n2o           12131\n",
      "                                total_ghg           12781\n",
      "                 total_ghg_excluding_lucf           12955\n",
      "                                trade_co2           45656\n",
      "                          trade_co2_share           45656\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Total missing values in entire dataset: 2,105,991\n",
      "Percentage of missing values: 53.113335\n"
     ]
    }
   ],
   "source": [
    "# Check for missing/null values\n",
    "missing_per_col = df.isnull().sum()\n",
    "missing_per_col_df = missing_per_col.reset_index()\n",
    "missing_per_col_df.columns = ['Column', 'Missing Values']\n",
    "print(\"\\nTotal number of missing values per column:\\n\")\n",
    "print(missing_per_col_df.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "total_missing = missing_per_col.sum()\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "percent_missing = (total_missing / total_cells) * 100\n",
    "print(f\"\\nTotal missing values in entire dataset: {total_missing:,}\")\n",
    "print(f\"Percentage of missing values: {percent_missing:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9ea88d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with empty strings:\n",
      "No empty strings found\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Data Types:\n",
      "country                         object\n",
      "year                             int64\n",
      "iso_code                        object\n",
      "population                     float64\n",
      "gdp                            float64\n",
      "                                ...   \n",
      "temperature_change_from_n2o    float64\n",
      "total_ghg                      float64\n",
      "total_ghg_excluding_lucf       float64\n",
      "trade_co2                      float64\n",
      "trade_co2_share                float64\n",
      "Length: 79, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for empty strings and other types of missing data\n",
    "print(\"Columns with empty strings:\")\n",
    "empty_strings = {}\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  # String columns\n",
    "        empty_count = (df[col] == '').sum()\n",
    "        if empty_count > 0:\n",
    "            empty_strings[col] = empty_count\n",
    "\n",
    "if empty_strings:\n",
    "    for col, count in empty_strings.items():\n",
    "        print(f\"{col}: {count} empty strings\")\n",
    "else:\n",
    "    print(\"No empty strings found\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098c1610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALYSIS FOR YEARS > 1830\n",
      "================================================================================\n",
      "\n",
      "Number of rows with year > 1830: 45209\n",
      "Dataset Shape (years > 1830): (45209, 79)\n",
      "\n",
      "Year range: 1832 to 2023\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "      <th>cement_co2</th>\n",
       "      <th>cement_co2_per_capita</th>\n",
       "      <th>co2</th>\n",
       "      <th>co2_growth_abs</th>\n",
       "      <th>co2_growth_prct</th>\n",
       "      <th>...</th>\n",
       "      <th>share_global_other_co2</th>\n",
       "      <th>share_of_temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_ch4</th>\n",
       "      <th>temperature_change_from_co2</th>\n",
       "      <th>temperature_change_from_ghg</th>\n",
       "      <th>temperature_change_from_n2o</th>\n",
       "      <th>total_ghg</th>\n",
       "      <th>total_ghg_excluding_lucf</th>\n",
       "      <th>trade_co2</th>\n",
       "      <th>trade_co2_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1832</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3460553.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1833</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3476034.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1834</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3491585.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1835</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3507205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1836</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3522896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        country  year iso_code  population  gdp  cement_co2  \\\n",
       "82  Afghanistan  1832      AFG   3460553.0  NaN         0.0   \n",
       "83  Afghanistan  1833      AFG   3476034.0  NaN         0.0   \n",
       "84  Afghanistan  1834      AFG   3491585.0  NaN         0.0   \n",
       "85  Afghanistan  1835      AFG   3507205.0  NaN         0.0   \n",
       "86  Afghanistan  1836      AFG   3522896.0  NaN         0.0   \n",
       "\n",
       "    cement_co2_per_capita  co2  co2_growth_abs  co2_growth_prct  ...  \\\n",
       "82                    0.0  NaN             NaN              NaN  ...   \n",
       "83                    0.0  NaN             NaN              NaN  ...   \n",
       "84                    0.0  NaN             NaN              NaN  ...   \n",
       "85                    0.0  NaN             NaN              NaN  ...   \n",
       "86                    0.0  NaN             NaN              NaN  ...   \n",
       "\n",
       "    share_global_other_co2  share_of_temperature_change_from_ghg  \\\n",
       "82                     NaN                                   NaN   \n",
       "83                     NaN                                   NaN   \n",
       "84                     NaN                                   NaN   \n",
       "85                     NaN                                   NaN   \n",
       "86                     NaN                                   NaN   \n",
       "\n",
       "    temperature_change_from_ch4  temperature_change_from_co2  \\\n",
       "82                          NaN                          NaN   \n",
       "83                          NaN                          NaN   \n",
       "84                          NaN                          NaN   \n",
       "85                          NaN                          NaN   \n",
       "86                          NaN                          NaN   \n",
       "\n",
       "    temperature_change_from_ghg  temperature_change_from_n2o  total_ghg  \\\n",
       "82                          NaN                          NaN        NaN   \n",
       "83                          NaN                          NaN        NaN   \n",
       "84                          NaN                          NaN        NaN   \n",
       "85                          NaN                          NaN        NaN   \n",
       "86                          NaN                          NaN        NaN   \n",
       "\n",
       "    total_ghg_excluding_lucf  trade_co2  trade_co2_share  \n",
       "82                       NaN        NaN              NaN  \n",
       "83                       NaN        NaN              NaN  \n",
       "84                       NaN        NaN              NaN  \n",
       "85                       NaN        NaN              NaN  \n",
       "86                       NaN        NaN              NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter dataset for years > 1830\n",
    "df_1830 = df[df['year'] > 1831].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALYSIS FOR YEARS > 1830\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumber of rows with year > 1830: {len(df_1830)}\")\n",
    "print(f\"Dataset Shape (years > 1830): {df_1830.shape}\")\n",
    "print(f\"\\nYear range: {df_1830['year'].min()} to {df_1830['year'].max()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_1830.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "378e9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the filtered dataset (years > 1830)\n",
    "df_cleaned = df_1830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3255458e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same-measure groups defined:\n",
      "  Group 1: ['share_global_co2', 'share_global_cumulative_co2']\n",
      "  Group 2: ['share_global_co2_including_luc', 'share_global_cumulative_co2_including_luc']\n",
      "  Group 3: ['share_global_cement_co2', 'share_global_cumulative_cement_co2']\n",
      "  Group 4: ['share_global_coal_co2', 'share_global_cumulative_coal_co2']\n",
      "  Group 5: ['share_global_oil_co2', 'share_global_cumulative_oil_co2']\n",
      "  Group 6: ['share_global_gas_co2', 'share_global_cumulative_gas_co2']\n",
      "  Group 7: ['share_global_flaring_co2', 'share_global_cumulative_flaring_co2']\n",
      "  Group 8: ['share_global_luc_co2', 'share_global_cumulative_luc_co2']\n",
      "  Group 9: ['share_global_other_co2', 'share_global_cumulative_other_co2']\n",
      "\n",
      "Total groups: 9\n"
     ]
    }
   ],
   "source": [
    "same_measure_groups = [\n",
    "    ['share_global_co2', 'share_global_cumulative_co2'],\n",
    "    ['share_global_co2_including_luc', 'share_global_cumulative_co2_including_luc'],\n",
    "    ['share_global_cement_co2', 'share_global_cumulative_cement_co2'],\n",
    "    ['share_global_coal_co2', 'share_global_cumulative_coal_co2'],\n",
    "    ['share_global_oil_co2', 'share_global_cumulative_oil_co2'],\n",
    "    ['share_global_gas_co2', 'share_global_cumulative_gas_co2'],\n",
    "    ['share_global_flaring_co2', 'share_global_cumulative_flaring_co2'],\n",
    "    ['share_global_luc_co2', 'share_global_cumulative_luc_co2'],\n",
    "    ['share_global_other_co2', 'share_global_cumulative_other_co2'],\n",
    "]\n",
    "\n",
    "print(\"Same-measure groups defined:\")\n",
    "for i, group in enumerate(same_measure_groups, 1):\n",
    "    print(f\"  Group {i}: {group}\")\n",
    "print(f\"\\nTotal groups: {len(same_measure_groups)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2099d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Same-measure analysis:\n",
      "Found 9 redundant pairs within same-measure groups\n",
      "\n",
      "Columns to be removed (same-measure): 9\n",
      "\n",
      "Redundant pairs by group (first 20):\n",
      "  share_global_co2 <-> share_global_cumulative_co2: 0.9826\n",
      "  share_global_co2_including_luc <-> share_global_cumulative_co2_including_luc: 0.9817\n",
      "  share_global_cement_co2 <-> share_global_cumulative_cement_co2: 0.9835\n",
      "  share_global_coal_co2 <-> share_global_cumulative_coal_co2: 0.9703\n",
      "  share_global_oil_co2 <-> share_global_cumulative_oil_co2: 0.9890\n",
      "  share_global_gas_co2 <-> share_global_cumulative_gas_co2: 0.9920\n",
      "  share_global_flaring_co2 <-> share_global_cumulative_flaring_co2: 0.9700\n",
      "  share_global_luc_co2 <-> share_global_cumulative_luc_co2: 0.9430\n",
      "  share_global_other_co2 <-> share_global_cumulative_other_co2: 0.9776\n"
     ]
    }
   ],
   "source": [
    "# Same-measure correlation analysis - only compare within same-measure groups\n",
    "threshold = 0.90\n",
    "same_measure_redundant_pairs = []\n",
    "columns_to_remove_same_measure = set()\n",
    "\n",
    "numeric_cols = df_cleaned.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# For each same-measure group, check correlation\n",
    "for group in same_measure_groups:\n",
    "    # Filter to only columns that exist in dataframe and are numeric\n",
    "    group_numeric = [col for col in group if col in numeric_cols and col in df_cleaned.columns]\n",
    "    \n",
    "    if len(group_numeric) < 2:\n",
    "        continue  # Need at least 2 columns to compare\n",
    "    \n",
    "    # Calculate correlation for this group\n",
    "    group_data = df_cleaned[group_numeric]\n",
    "    group_corr = group_data.corr()\n",
    "    \n",
    "    # Check all pairs in this group\n",
    "    for i in range(len(group_corr.columns)):\n",
    "        for j in range(i+1, len(group_corr.columns)):\n",
    "            col1 = group_corr.columns[i]\n",
    "            col2 = group_corr.columns[j]\n",
    "            \n",
    "            # Skip if either already marked for removal\n",
    "            if col1 in columns_to_remove_same_measure or col2 in columns_to_remove_same_measure:\n",
    "                continue\n",
    "            \n",
    "            corr_value = group_corr.iloc[i, j]\n",
    "            if pd.notna(corr_value) and abs(corr_value) >= threshold:\n",
    "                same_measure_redundant_pairs.append({\n",
    "                    'group': group,\n",
    "                    'col1': col1,\n",
    "                    'col2': col2,\n",
    "                    'correlation': corr_value\n",
    "                })\n",
    "                \n",
    "                # Count missing values and decide which to remove\n",
    "                missing_col1 = df_cleaned[col1].isnull().sum()\n",
    "                missing_col2 = df_cleaned[col2].isnull().sum()\n",
    "                \n",
    "                # Keep the one with fewer missing values\n",
    "                if missing_col1 <= missing_col2:\n",
    "                    columns_to_remove_same_measure.add(col2)\n",
    "                else:\n",
    "                    columns_to_remove_same_measure.add(col1)\n",
    "\n",
    "print(f\"\\nSame-measure analysis:\")\n",
    "print(f\"Found {len(same_measure_redundant_pairs)} redundant pairs within same-measure groups\")\n",
    "if len(same_measure_redundant_pairs) > 0:\n",
    "    print(f\"\\nColumns to be removed (same-measure): {len(columns_to_remove_same_measure)}\")\n",
    "    print(\"\\nRedundant pairs by group (first 20):\")\n",
    "    for pair in same_measure_redundant_pairs[:20]:\n",
    "        print(f\"  {pair['col1']} <-> {pair['col2']}: {pair['correlation']:.4f}\")\n",
    "    if len(same_measure_redundant_pairs) > 20:\n",
    "        print(f\"  ... and {len(same_measure_redundant_pairs) - 20} more pairs\")\n",
    "else:\n",
    "    print(\"No redundant columns found within same-measure groups!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1376c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original number of columns: 79\n",
      "After removing same-measure redundant columns: 70\n",
      "Removed 9 redundant columns\n",
      "\n",
      "Removed columns: ['share_global_cumulative_cement_co2', 'share_global_cumulative_co2', 'share_global_cumulative_co2_including_luc', 'share_global_cumulative_coal_co2', 'share_global_cumulative_flaring_co2', 'share_global_cumulative_gas_co2', 'share_global_cumulative_luc_co2', 'share_global_cumulative_oil_co2', 'share_global_cumulative_other_co2']\n"
     ]
    }
   ],
   "source": [
    "# Remove same-measure redundant columns\n",
    "df_same_measure = df_cleaned.copy()\n",
    "\n",
    "print(f\"\\nOriginal number of columns: {len(df_same_measure.columns)}\")\n",
    "if len(columns_to_remove_same_measure) > 0:\n",
    "    df_same_measure = df_same_measure.drop(columns=list(columns_to_remove_same_measure))\n",
    "    print(f\"After removing same-measure redundant columns: {len(df_same_measure.columns)}\")\n",
    "    print(f\"Removed {len(columns_to_remove_same_measure)} redundant columns\")\n",
    "    print(f\"\\nRemoved columns: {sorted(list(columns_to_remove_same_measure))}\")\n",
    "else:\n",
    "    print(\"No columns to remove - keeping all columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d24442fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns have mappings!\n",
      "\n",
      "Total columns to rename: 79\n"
     ]
    }
   ],
   "source": [
    "column_name_mapping = {\n",
    "    # Basic Identifiers\n",
    "    'country': 'Country',\n",
    "    'year': 'Year',\n",
    "    'iso_code': 'ISO Country Code',\n",
    "    \n",
    "    # Demographics & Economy\n",
    "    'population': 'Population',\n",
    "    'gdp': 'Gross Domestic Product',\n",
    "    \n",
    "    # CO2 Emissions by source\n",
    "    'cement_co2': 'Cement CO2 Emissions',\n",
    "    'cement_co2_per_capita': 'Cement CO2 Per Capita',\n",
    "    'coal_co2': 'Coal CO2 Emissions',\n",
    "    'coal_co2_per_capita': 'Coal CO2 Per Capita',\n",
    "    'oil_co2': 'Oil CO2 Emissions',\n",
    "    'oil_co2_per_capita': 'Oil CO2 Per Capita',\n",
    "    'gas_co2': 'Gas CO2 Emissions',\n",
    "    'gas_co2_per_capita': 'Gas CO2 Per Capita',\n",
    "    'flaring_co2': 'Flaring CO2 Emissions',\n",
    "    'flaring_co2_per_capita': 'Flaring CO2 Per Capita',\n",
    "    'land_use_change_co2': 'Land Use Change CO2',\n",
    "    'land_use_change_co2_per_capita': 'Land Use Change CO2 Per Capita',\n",
    "    'other_industry_co2': 'Other Industry CO2',\n",
    "    'other_co2_per_capita': 'Other CO2 Per Capita',\n",
    "    \n",
    "    # Total CO2 Metrics\n",
    "    'co2': 'CO2 Emissions',\n",
    "    'co2_including_luc': 'CO2 Including Land Use Change',\n",
    "    'co2_growth_abs': 'CO2 Growth Absolute',\n",
    "    'co2_growth_prct': 'CO2 Growth Percentage',\n",
    "    'co2_per_capita': 'CO2 Per Capita',\n",
    "    'co2_per_gdp': 'CO2 Per GDP',\n",
    "    'co2_per_unit_energy': 'CO2 Per Unit Energy',\n",
    "    'co2_including_luc_growth_abs': 'CO2 Including Land Use Change Growth Absolute',\n",
    "    'co2_including_luc_growth_prct': 'CO2 Including Land Use Change Growth Percentage',\n",
    "    'co2_including_luc_per_capita': 'CO2 Including Land Use Change Per Capita',\n",
    "    'co2_including_luc_per_gdp': 'CO2 Including Land Use Change Per GDP',\n",
    "    'co2_including_luc_per_unit_energy': 'CO2 Including Land Use Change Per Unit Energy',\n",
    "    \n",
    "    # Cumulative Emissions\n",
    "    'cumulative_co2': 'Cumulative CO2',\n",
    "    'cumulative_co2_including_luc': 'Cumulative CO2 Including Land Use Change',\n",
    "    'cumulative_cement_co2': 'Cumulative Cement CO2',\n",
    "    'cumulative_coal_co2': 'Cumulative Coal CO2',\n",
    "    'cumulative_oil_co2': 'Cumulative Oil CO2',\n",
    "    'cumulative_gas_co2': 'Cumulative Gas CO2',\n",
    "    'cumulative_flaring_co2': 'Cumulative Flaring CO2',\n",
    "    'cumulative_luc_co2': 'Cumulative Land Use Change CO2',\n",
    "    'cumulative_other_co2': 'Cumulative Other CO2',\n",
    "    \n",
    "    # Energy Metrics\n",
    "    'primary_energy_consumption': 'Primary Energy Consumption',\n",
    "    'energy_per_capita': 'Energy Per Capita',\n",
    "    'energy_per_gdp': 'Energy Per GDP',\n",
    "    \n",
    "    # Other Greenhouse Gases\n",
    "    'methane': 'Methane',\n",
    "    'methane_per_capita': 'Methane Per Capita',\n",
    "    'nitrous_oxide': 'Nitrous Oxide',\n",
    "    'nitrous_oxide_per_capita': 'Nitrous Oxide Per Capita',\n",
    "    'ghg_per_capita': 'Greenhouse Gas Per Capita',\n",
    "    'ghg_excluding_lucf_per_capita': 'Greenhouse Gas Excluding Land Use Change Per Capita',\n",
    "    'total_ghg': 'Total Greenhouse Gas',\n",
    "    'total_ghg_excluding_lucf': 'Total Greenhouse Gas Excluding Land Use Change',\n",
    "    \n",
    "    # Global Shares\n",
    "    'share_global_co2': 'Share of Global CO2',\n",
    "    'share_global_co2_including_luc': 'Share of Global CO2 Including Land Use Change',\n",
    "    'share_global_cumulative_co2': 'Share of Global Cumulative CO2',\n",
    "    'share_global_cumulative_co2_including_luc': 'Share of Global Cumulative CO2 Including Land Use Change',\n",
    "    'share_global_cement_co2': 'Share of Global Cement CO2',\n",
    "    'share_global_cumulative_cement_co2': 'Share of Global Cumulative Cement CO2',\n",
    "    'share_global_coal_co2': 'Share of Global Coal CO2',\n",
    "    'share_global_cumulative_coal_co2': 'Share of Global Cumulative Coal CO2',\n",
    "    'share_global_oil_co2': 'Share of Global Oil CO2',\n",
    "    'share_global_cumulative_oil_co2': 'Share of Global Cumulative Oil CO2',\n",
    "    'share_global_gas_co2': 'Share of Global Gas CO2',\n",
    "    'share_global_cumulative_gas_co2': 'Share of Global Cumulative Gas CO2',\n",
    "    'share_global_flaring_co2': 'Share of Global Flaring CO2',\n",
    "    'share_global_cumulative_flaring_co2': 'Share of Global Cumulative Flaring CO2',\n",
    "    'share_global_luc_co2': 'Share of Global Land Use Change CO2',\n",
    "    'share_global_cumulative_luc_co2': 'Share of Global Cumulative Land Use Change CO2',\n",
    "    'share_global_other_co2': 'Share of Global Other CO2',\n",
    "    'share_global_cumulative_other_co2': 'Share of Global Cumulative Other CO2',\n",
    "    \n",
    "    # Climate Impact\n",
    "    'temperature_change_from_co2': 'Temperature Change From CO2',\n",
    "    'temperature_change_from_ch4': 'Temperature Change From Methane',\n",
    "    'temperature_change_from_n2o': 'Temperature Change From Nitrous Oxide',\n",
    "    'temperature_change_from_ghg': 'Temperature Change From Greenhouse Gas',\n",
    "    'share_of_temperature_change_from_ghg': 'Share of Temperature Change From Greenhouse Gas',\n",
    "    \n",
    "    # Trade\n",
    "    'trade_co2': 'Trade CO2',\n",
    "    'trade_co2_share': 'Trade CO2 Share',\n",
    "    'consumption_co2': 'Consumption CO2',\n",
    "    'consumption_co2_per_capita': 'Consumption CO2 Per Capita',\n",
    "    'consumption_co2_per_gdp': 'Consumption CO2 Per GDP',\n",
    "}\n",
    "\n",
    "# Check if all columns have mappings\n",
    "missing_mappings = [col for col in df_cleaned.columns if col not in column_name_mapping]\n",
    "if missing_mappings:\n",
    "    print(f\"Warning: {len(missing_mappings)} columns don't have mappings:\")\n",
    "    for col in missing_mappings:\n",
    "        print(f\"  - {col}\")\n",
    "        # Create a default mapping by replacing underscores and capitalizing\n",
    "        default_name = col.replace('_', ' ').title()\n",
    "        column_name_mapping[col] = default_name\n",
    "else:\n",
    "    print(\"All columns have mappings!\")\n",
    "\n",
    "print(f\"\\nTotal columns to rename: {len(df_cleaned.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eae687c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAME-MEASURE CLEANING COMPLETE (Approach C)\n",
      "================================================================================\n",
      "\n",
      "Renamed 70 columns\n",
      "\n",
      "Final dataset shape: (45209, 70)\n",
      "Rows: 45,209\n",
      "Columns: 70\n",
      "\n",
      "Year range: 1832 to 2023\n",
      "\n",
      "Sample of renamed columns (first 10):\n",
      "  country -> Country\n",
      "  year -> Year\n",
      "  iso_code -> ISO Country Code\n",
      "  population -> Population\n",
      "  gdp -> Gross Domestic Product\n",
      "  cement_co2 -> Cement CO2 Emissions\n",
      "  cement_co2_per_capita -> Cement CO2 Per Capita\n",
      "  coal_co2 -> Coal CO2 Emissions\n",
      "  coal_co2_per_capita -> Coal CO2 Per Capita\n",
      "  oil_co2 -> Oil CO2 Emissions\n",
      "  ... and 60 more columns\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for same-measure dataframe\n",
    "existing_mapping_same_measure = {k: v for k, v in column_name_mapping.items() if k in df_same_measure.columns}\n",
    "df_same_measure_renamed = df_same_measure.rename(columns=existing_mapping_same_measure)\n",
    "\n",
    "# Handle any unmapped columns\n",
    "missing_mappings_same_measure = [col for col in df_same_measure_renamed.columns if col not in existing_mapping_same_measure.values() and col not in existing_mapping_same_measure.keys()]\n",
    "for col in missing_mappings_same_measure:\n",
    "    if col in df_same_measure.columns:\n",
    "        default_name = col.replace('_', ' ').title()\n",
    "        df_same_measure_renamed = df_same_measure_renamed.rename(columns={col: default_name})\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAME-MEASURE CLEANING COMPLETE (Approach C)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nRenamed {len(existing_mapping_same_measure)} columns\")\n",
    "print(f\"\\nFinal dataset shape: {df_same_measure_renamed.shape}\")\n",
    "print(f\"Rows: {df_same_measure_renamed.shape[0]:,}\")\n",
    "print(f\"Columns: {df_same_measure_renamed.shape[1]}\")\n",
    "print(f\"\\nYear range: {df_same_measure_renamed['Year'].min()} to {df_same_measure_renamed['Year'].max()}\")\n",
    "print(\"\\nSample of renamed columns (first 10):\")\n",
    "for old_name, new_name in list(existing_mapping_same_measure.items())[:10]:\n",
    "    print(f\"  {old_name} -> {new_name}\")\n",
    "if len(existing_mapping_same_measure) > 10:\n",
    "    print(f\"  ... and {len(existing_mapping_same_measure) - 10} more columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ced41d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFYING DERIVED COLUMNS\n",
      "================================================================================\n",
      "\n",
      "Dataset Shape: (45209, 70)\n",
      "Total Columns: 70\n",
      "25\n",
      "\n",
      "Base Columns: 25\n",
      "Base columns: Country, Year, ISO Country Code, Population, Gross Domestic Product, CO2 Emissions, CO2 Including Land Use Change, Coal CO2 Emissions, Oil CO2 Emissions, Gas CO2 Emissions...\n",
      "\n",
      "Derived Columns (candidates for removal): 45\n",
      "Sample derived columns: CO2 Growth Absolute, CO2 Growth Percentage, CO2 Including Land Use Change Growth Absolute, CO2 Including Land Use Change Growth Percentage, CO2 Including Land Use Change Per Capita, CO2 Including Land Use Change Per GDP, CO2 Including Land Use Change Per Unit Energy, CO2 Per Capita, CO2 Per GDP, CO2 Per Unit Energy...\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset\n",
    "df_verify = df_same_measure_renamed\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING DERIVED COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset Shape: {df_verify.shape}\")\n",
    "print(f\"Total Columns: {len(df_verify.columns)}\")\n",
    "\n",
    "\n",
    "# Define base columns (direct measurements - cannot be derived)\n",
    "base_columns = [\n",
    "    # Identifiers\n",
    "    'Country', 'Year', 'ISO Country Code',\n",
    "    # Demographics\n",
    "    'Population', 'Gross Domestic Product',\n",
    "    # CO2 by source\n",
    "    'CO2 Emissions', 'CO2 Including Land Use Change',\n",
    "    'Coal CO2 Emissions', 'Oil CO2 Emissions', 'Gas CO2 Emissions',\n",
    "    'Cement CO2 Emissions', 'Flaring CO2 Emissions',\n",
    "    'Land Use Change CO2', 'Other Industry CO2',\n",
    "    # Energy\n",
    "    'Primary Energy Consumption',\n",
    "    # Other GHGs\n",
    "    'Methane', 'Nitrous Oxide',\n",
    "    'Total Greenhouse Gas', 'Total Greenhouse Gas Excluding Land Use Change',\n",
    "    # Climate\n",
    "    'Temperature Change From CO2', 'Temperature Change From Methane',\n",
    "    'Temperature Change From Nitrous Oxide', 'Temperature Change From Greenhouse Gas',\n",
    "    # Trade\n",
    "    'Trade CO2', 'Consumption CO2',\n",
    "]\n",
    "\n",
    "print(len(base_columns))\n",
    "\n",
    "# Filter to only columns that exist\n",
    "base_columns = [col for col in base_columns if col in df_verify.columns]\n",
    "\n",
    "print(f\"\\nBase Columns: {len(base_columns)}\")\n",
    "print(f\"Base columns: {', '.join(base_columns[:10])}...\")\n",
    "\n",
    "# Derived columns are all others\n",
    "all_columns = set(df_verify.columns)\n",
    "derived_columns = sorted(list(all_columns - set(base_columns)))\n",
    "\n",
    "print(f\"\\nDerived Columns (candidates for removal): {len(derived_columns)}\")\n",
    "print(f\"Sample derived columns: {', '.join(derived_columns[:10])}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64348d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total derived relationships to verify: 45\n",
      "\n",
      "Breakdown by type:\n",
      "  Per-capita: 15\n",
      "  Per-GDP: 4\n",
      "  Per-unit energy: 2\n",
      "  Cumulative: 9\n",
      "  Share of global: 10\n",
      "  Growth: 4\n",
      "  Trade share: 1\n"
     ]
    }
   ],
   "source": [
    "# Define expected derived column relationships\n",
    "derived_relationships = []\n",
    "\n",
    "# Per-capita columns: X / Population * 1e6\n",
    "per_capita_mappings = {\n",
    "    'CO2 Emissions': 'CO2 Per Capita',\n",
    "    'CO2 Including Land Use Change': 'CO2 Including Land Use Change Per Capita',\n",
    "    'Coal CO2 Emissions': 'Coal CO2 Per Capita',\n",
    "    'Oil CO2 Emissions': 'Oil CO2 Per Capita',\n",
    "    'Gas CO2 Emissions': 'Gas CO2 Per Capita',\n",
    "    'Cement CO2 Emissions': 'Cement CO2 Per Capita',\n",
    "    'Flaring CO2 Emissions': 'Flaring CO2 Per Capita',\n",
    "    'Land Use Change CO2': 'Land Use Change CO2 Per Capita',\n",
    "    'Other Industry CO2': 'Other CO2 Per Capita',\n",
    "    'Methane': 'Methane Per Capita',\n",
    "    'Nitrous Oxide': 'Nitrous Oxide Per Capita',\n",
    "    'Total Greenhouse Gas': 'Greenhouse Gas Per Capita',\n",
    "    'Total Greenhouse Gas Excluding Land Use Change': 'Greenhouse Gas Excluding Land Use Change Per Capita',\n",
    "    'Consumption CO2': 'Consumption CO2 Per Capita',\n",
    "    'Primary Energy Consumption': 'Energy Per Capita',\n",
    "}\n",
    "\n",
    "for base_col, derived_col in per_capita_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col, 'Population'],\n",
    "            'formula': f'{base_col} / Population * 1e6',\n",
    "            'type': 'Per-capita'\n",
    "        })\n",
    "\n",
    "# Per-GDP columns: X / GDP\n",
    "per_gdp_mappings = {\n",
    "    'CO2 Emissions': 'CO2 Per GDP',\n",
    "    'CO2 Including Land Use Change': 'CO2 Including Land Use Change Per GDP',\n",
    "    'Consumption CO2': 'Consumption CO2 Per GDP',\n",
    "    'Primary Energy Consumption': 'Energy Per GDP',\n",
    "}\n",
    "\n",
    "for base_col, derived_col in per_gdp_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col, 'Gross Domestic Product'],\n",
    "            'formula': f'{base_col} / GDP',\n",
    "            'type': 'Per-GDP'\n",
    "        })\n",
    "\n",
    "# Per-unit energy columns: X / Energy\n",
    "per_unit_energy_mappings = {\n",
    "    'CO2 Emissions': 'CO2 Per Unit Energy',\n",
    "    'CO2 Including Land Use Change': 'CO2 Including Land Use Change Per Unit Energy',\n",
    "}\n",
    "\n",
    "for base_col, derived_col in per_unit_energy_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col, 'Primary Energy Consumption'],\n",
    "            'formula': f'{base_col} / Primary Energy Consumption',\n",
    "            'type': 'Per-unit energy'\n",
    "        })\n",
    "\n",
    "# Cumulative columns: cumsum(X) per country\n",
    "cumulative_mappings = {\n",
    "    'CO2 Emissions': 'Cumulative CO2',\n",
    "    'CO2 Including Land Use Change': 'Cumulative CO2 Including Land Use Change',\n",
    "    'Coal CO2 Emissions': 'Cumulative Coal CO2',\n",
    "    'Oil CO2 Emissions': 'Cumulative Oil CO2',\n",
    "    'Gas CO2 Emissions': 'Cumulative Gas CO2',\n",
    "    'Cement CO2 Emissions': 'Cumulative Cement CO2',\n",
    "    'Flaring CO2 Emissions': 'Cumulative Flaring CO2',\n",
    "    'Land Use Change CO2': 'Cumulative Land Use Change CO2',\n",
    "    'Other Industry CO2': 'Cumulative Other CO2',\n",
    "}\n",
    "\n",
    "for base_col, derived_col in cumulative_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col],\n",
    "            'formula': f'cumsum({base_col}) per country',\n",
    "            'type': 'Cumulative'\n",
    "        })\n",
    "\n",
    "# Share of global columns: X / Global_X * 100\n",
    "share_mappings = {\n",
    "    'CO2 Emissions': 'Share of Global CO2',\n",
    "    'CO2 Including Land Use Change': 'Share of Global CO2 Including Land Use Change',\n",
    "    'Coal CO2 Emissions': 'Share of Global Coal CO2',\n",
    "    'Oil CO2 Emissions': 'Share of Global Oil CO2',\n",
    "    'Gas CO2 Emissions': 'Share of Global Gas CO2',\n",
    "    'Cement CO2 Emissions': 'Share of Global Cement CO2',\n",
    "    'Flaring CO2 Emissions': 'Share of Global Flaring CO2',\n",
    "    'Land Use Change CO2': 'Share of Global Land Use Change CO2',\n",
    "    'Temperature Change From Greenhouse Gas': 'Share of Temperature Change From Greenhouse Gas',\n",
    "    'Other Industry CO2': 'Share of Global Other CO2',\n",
    "}\n",
    "\n",
    "for base_col, derived_col in share_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col],\n",
    "            'formula': f'{base_col} / Global_{base_col} * 100',\n",
    "            'type': 'Share of global'\n",
    "        })\n",
    "\n",
    "# Growth metrics\n",
    "growth_mappings = {\n",
    "    ('CO2 Emissions', 'CO2 Growth Absolute'): 'diff',\n",
    "    ('CO2 Emissions', 'CO2 Growth Percentage'): 'pct_change',\n",
    "    ('CO2 Including Land Use Change', 'CO2 Including Land Use Change Growth Absolute'): 'diff',\n",
    "    ('CO2 Including Land Use Change', 'CO2 Including Land Use Change Growth Percentage'): 'pct_change',\n",
    "}\n",
    "\n",
    "for (base_col, derived_col), method in growth_mappings.items():\n",
    "    if base_col in df_verify.columns and derived_col in df_verify.columns:\n",
    "        derived_relationships.append({\n",
    "            'derived_col': derived_col,\n",
    "            'base_cols': [base_col],\n",
    "            'formula': f'{method}({base_col})',\n",
    "            'type': 'Growth'\n",
    "        })\n",
    "\n",
    "# Trade share\n",
    "if 'Trade CO2' in df_verify.columns and 'CO2 Emissions' in df_verify.columns and 'Trade CO2 Share' in df_verify.columns:\n",
    "    derived_relationships.append({\n",
    "        'derived_col': 'Trade CO2 Share',\n",
    "        'base_cols': ['Trade CO2', 'CO2 Emissions'],\n",
    "        'formula': 'Trade CO2 / CO2 Emissions * 100',\n",
    "        'type': 'Trade share'\n",
    "    })\n",
    "\n",
    "print(f\"\\nTotal derived relationships to verify: {len(derived_relationships)}\")\n",
    "print(f\"\\nBreakdown by type:\")\n",
    "from collections import Counter\n",
    "type_counts = Counter([r['type'] for r in derived_relationships])\n",
    "for dtype, count in type_counts.items():\n",
    "    print(f\"  {dtype}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "79032cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFYING DERIVED COLUMNS WITH R\n",
      "================================================================================\n",
      "\n",
      "Verification complete for 45 derived columns\n"
     ]
    }
   ],
   "source": [
    "# Verify each derived column using R-squared\n",
    "verification_results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFYING DERIVED COLUMNS WITH R\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rel in derived_relationships:\n",
    "    derived_col = rel['derived_col']\n",
    "    base_cols = rel['base_cols']\n",
    "    formula_type = rel['type']\n",
    "    \n",
    "    # Check if all required columns exist\n",
    "    if not all(col in df_verify.columns for col in base_cols + [derived_col]):\n",
    "        continue\n",
    "    \n",
    "    # Get rows where both derived and base columns are not null\n",
    "    mask = df_verify[derived_col].notna()\n",
    "    for col in base_cols:\n",
    "        mask = mask & df_verify[col].notna()\n",
    "    \n",
    "    if mask.sum() == 0:\n",
    "        verification_results.append({\n",
    "            'derived_col': derived_col,\n",
    "            'type': formula_type,\n",
    "            'formula': rel['formula'],\n",
    "            'r2': np.nan,\n",
    "            'n_samples': 0,\n",
    "            'verified': False,\n",
    "            'reason': 'No overlapping non-null values'\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Calculate derived value based on formula type\n",
    "    calculated = None\n",
    "    \n",
    "    if formula_type == 'Per-capita':\n",
    "        base_col = base_cols[0]\n",
    "        calculated = (df_verify[base_col] / df_verify['Population']) * 1e6\n",
    "    \n",
    "    elif formula_type == 'Per-GDP':\n",
    "        base_col = base_cols[0]\n",
    "        calculated = df_verify[base_col] / df_verify['Gross Domestic Product']\n",
    "        # Handle division by zero\n",
    "        calculated = np.where(df_verify['Gross Domestic Product'] != 0, calculated, np.nan)\n",
    "    \n",
    "    elif formula_type == 'Per-unit energy':\n",
    "        base_col = base_cols[0]\n",
    "        calculated = df_verify[base_col] / df_verify['Primary Energy Consumption']\n",
    "        calculated = np.where(df_verify['Primary Energy Consumption'] != 0, calculated, np.nan)\n",
    "    \n",
    "    elif formula_type == 'Cumulative':\n",
    "        base_col = base_cols[0]\n",
    "        # Sort by country and year, then compute cumulative sum\n",
    "        df_sorted = df_verify.sort_values(['Country', 'Year']).copy()\n",
    "        calculated_series = df_sorted.groupby('Country')[base_col].cumsum()\n",
    "        # Create a series aligned with original dataframe\n",
    "        calculated = pd.Series(index=df_verify.index, dtype=float)\n",
    "        calculated.loc[df_sorted.index] = calculated_series.values\n",
    "    \n",
    "    elif formula_type == 'Share of global':\n",
    "        base_col = base_cols[0]\n",
    "        # Compute global total per year\n",
    "        global_totals = df_verify.groupby('Year')[base_col].transform('sum')\n",
    "        calculated_values = (df_verify[base_col] / global_totals) * 100\n",
    "        calculated = pd.Series(np.where(global_totals != 0, calculated_values, np.nan), index=df_verify.index)\n",
    "    \n",
    "    elif formula_type == 'Growth':\n",
    "        base_col = base_cols[0]\n",
    "        if 'Absolute' in derived_col:\n",
    "            # Absolute growth: diff\n",
    "            df_sorted = df_verify.sort_values(['Country', 'Year']).copy()\n",
    "            calculated_series = df_sorted.groupby('Country')[base_col].diff()\n",
    "            # Create a series aligned with original dataframe\n",
    "            calculated = pd.Series(index=df_verify.index, dtype=float)\n",
    "            calculated.loc[df_sorted.index] = calculated_series.values\n",
    "        else:\n",
    "            # Percentage growth: pct_change\n",
    "            df_sorted = df_verify.sort_values(['Country', 'Year']).copy()\n",
    "            prev_values = df_sorted.groupby('Country')[base_col].shift(1)\n",
    "            pct_change = ((df_sorted[base_col] - prev_values) / prev_values) * 100\n",
    "            pct_change_clean = np.where(prev_values != 0, pct_change, np.nan)\n",
    "            # Create a series aligned with original dataframe\n",
    "            calculated = pd.Series(index=df_verify.index, dtype=float)\n",
    "            calculated.loc[df_sorted.index] = pct_change_clean\n",
    "    \n",
    "    elif formula_type == 'Trade share':\n",
    "        calculated_values = (df_verify['Trade CO2'] / df_verify['CO2 Emissions']) * 100\n",
    "        calculated = pd.Series(np.where(df_verify['CO2 Emissions'] != 0, calculated_values, np.nan), index=df_verify.index)\n",
    "    \n",
    "    if calculated is None:\n",
    "        continue\n",
    "    \n",
    "    # Get actual values\n",
    "    actual = df_verify[derived_col]\n",
    "    \n",
    "    # Find overlapping non-null values\n",
    "    overlap_mask = mask & pd.notna(calculated) & pd.notna(actual)\n",
    "    \n",
    "    if overlap_mask.sum() < 10:  # Need at least 10 samples\n",
    "        verification_results.append({\n",
    "            'derived_col': derived_col,\n",
    "            'type': formula_type,\n",
    "            'formula': rel['formula'],\n",
    "            'pearson_r': np.nan,\n",
    "            'n_samples': overlap_mask.sum(),\n",
    "            'verified': False,\n",
    "            'reason': f'Insufficient samples ({overlap_mask.sum()})'\n",
    "        })\n",
    "        continue\n",
    "    \n",
    "    # Calculate Pearson correlation coefficient\n",
    "    actual_values = actual[overlap_mask]\n",
    "    calculated_values = calculated[overlap_mask]\n",
    "    \n",
    "    try:\n",
    "        # Use numpy corrcoef to get Pearson correlation coefficient\n",
    "        pearson_r = np.corrcoef(actual_values, calculated_values)[0, 1]\n",
    "        \n",
    "        # Verify if absolute Pearson r > 0.9 (catches both positive and negative correlations)\n",
    "        verified = abs(pearson_r) > 0.9\n",
    "        \n",
    "        verification_results.append({\n",
    "            'derived_col': derived_col,\n",
    "            'type': formula_type,\n",
    "            'formula': rel['formula'],\n",
    "            'pearson_r': pearson_r,\n",
    "            'n_samples': overlap_mask.sum(),\n",
    "            'verified': verified,\n",
    "            'reason': 'Verified' if verified else f'|r|={abs(pearson_r):.4f} < 0.9'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        verification_results.append({\n",
    "            'derived_col': derived_col,\n",
    "            'type': formula_type,\n",
    "            'formula': rel['formula'],\n",
    "            'pearson_r': np.nan,\n",
    "            'n_samples': overlap_mask.sum(),\n",
    "            'verified': False,\n",
    "            'reason': f'Error: {str(e)}'\n",
    "        })\n",
    "\n",
    "print(f\"\\nVerification complete for {len(verification_results)} derived columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67b3fcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICATION RESULTS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Verified (R > 0.9): 45 / 45 (100.0%)\n",
      "\n",
      "Results by type:\n",
      "           Type  Verified  Total  Percentage\n",
      "     Cumulative         9      9       100.0\n",
      "         Growth         4      4       100.0\n",
      "        Per-GDP         4      4       100.0\n",
      "     Per-capita        15     15       100.0\n",
      "Per-unit energy         2      2       100.0\n",
      "Share of global        10     10       100.0\n",
      "    Trade share         1      1       100.0\n",
      "\n",
      "================================================================================\n",
      "DETAILED RESULTS\n",
      "================================================================================\n",
      "\n",
      "Verified columns (can be removed):\n",
      "                                        derived_col            type  pearson_r  n_samples\n",
      "           Cumulative CO2 Including Land Use Change      Cumulative   1.000000      23585\n",
      "                     Cumulative Land Use Change CO2      Cumulative   1.000000      37236\n",
      "                                 Cumulative Oil CO2      Cumulative   1.000000      24187\n",
      "                                 Cumulative Gas CO2      Cumulative   1.000000      16984\n",
      "                              Cumulative Cement CO2      Cumulative   1.000000      24545\n",
      "                             Cumulative Flaring CO2      Cumulative   1.000000      14787\n",
      "                               Cumulative Other CO2      Cumulative   1.000000       2956\n",
      "      CO2 Including Land Use Change Growth Absolute          Growth   1.000000      23285\n",
      "                                CO2 Growth Absolute          Growth   1.000000      25473\n",
      "              CO2 Including Land Use Change Per GDP         Per-GDP   1.000000      14272\n",
      "                                     Energy Per GDP         Per-GDP   1.000000       7696\n",
      "                                    Trade CO2 Share     Trade share   1.000000       4501\n",
      "                             Flaring CO2 Per Capita      Per-capita   1.000000      13490\n",
      "                                        CO2 Per GDP         Per-GDP   1.000000      14620\n",
      "                            Consumption CO2 Per GDP         Per-GDP   0.999999       3916\n",
      "                          Greenhouse Gas Per Capita      Per-capita   0.999998      35813\n",
      "                                 Oil CO2 Per Capita      Per-capita   0.999996      22971\n",
      "Greenhouse Gas Excluding Land Use Change Per Capita      Per-capita   0.999995      35639\n",
      "                                     Cumulative CO2      Cumulative   0.999985      25816\n",
      "                                 Methane Per Capita      Per-capita   0.999983      35813\n",
      "                     Land Use Change CO2 Per Capita      Per-capita   0.999983      35648\n",
      "                                     CO2 Per Capita      Per-capita   0.999979      24511\n",
      "                                 Gas CO2 Per Capita      Per-capita   0.999971      15827\n",
      "                                Cumulative Coal CO2      Cumulative   0.999953      20835\n",
      "      CO2 Including Land Use Change Per Unit Energy Per-unit energy   0.999942       9406\n",
      "                           Nitrous Oxide Per Capita      Per-capita   0.999931      36320\n",
      "                              Cement CO2 Per Capita      Per-capita   0.999914      22707\n",
      "           CO2 Including Land Use Change Per Capita      Per-capita   0.999895      22715\n",
      "                         Consumption CO2 Per Capita      Per-capita   0.999778       4370\n",
      "                                Coal CO2 Per Capita      Per-capita   0.999771      19633\n",
      "                               Other CO2 Per Capita      Per-capita   0.999666       2324\n",
      "    CO2 Including Land Use Change Growth Percentage          Growth   0.999567      23285\n",
      "                          Share of Global Other CO2 Share of global   0.999527       2108\n",
      "                        Share of Global Flaring CO2 Share of global   0.998240      10869\n",
      "                                  Energy Per Capita      Per-capita   0.997912      10109\n",
      "                            Share of Global Oil CO2 Share of global   0.997182      23592\n",
      "                Share of Global Land Use Change CO2 Share of global   0.996622      37236\n",
      "    Share of Temperature Change From Greenhouse Gas Share of global   0.996138      41001\n",
      "                                CO2 Per Unit Energy Per-unit energy   0.996136      10055\n",
      "                            Share of Global Gas CO2 Share of global   0.996017      15034\n",
      "                           Share of Global Coal CO2 Share of global   0.995937      20835\n",
      "                                Share of Global CO2 Share of global   0.995937      25816\n",
      "      Share of Global CO2 Including Land Use Change Share of global   0.990440      23585\n",
      "                              CO2 Growth Percentage          Growth   0.989980      24875\n",
      "                         Share of Global Cement CO2 Share of global   0.989808      21563\n",
      "\n",
      "\n",
      "Not verified columns (keep or investigate):\n"
     ]
    }
   ],
   "source": [
    "# Display verification results\n",
    "results_df = pd.DataFrame(verification_results)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICATION RESULTS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Summary statistics\n",
    "verified_count = results_df['verified'].sum()\n",
    "total_count = len(results_df)\n",
    "print(f\"\\nVerified (R > 0.9): {verified_count} / {total_count} ({verified_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# Group by type\n",
    "print(\"\\nResults by type:\")\n",
    "type_summary = results_df.groupby('type').agg({\n",
    "    'verified': ['sum', 'count']\n",
    "}).reset_index()\n",
    "type_summary.columns = ['Type', 'Verified', 'Total']\n",
    "type_summary['Percentage'] = (type_summary['Verified'] / type_summary['Total'] * 100).round(1)\n",
    "print(type_summary.to_string(index=False))\n",
    "\n",
    "# Show detailed results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by verified status and R²\n",
    "results_df_sorted = results_df.sort_values(['verified', 'pearson_r'], ascending=[False, False])\n",
    "\n",
    "print(\"\\nVerified columns (can be removed):\")\n",
    "verified_cols = results_df_sorted[results_df_sorted['verified'] == True]\n",
    "if len(verified_cols) > 0:\n",
    "    display_cols = ['derived_col', 'type', 'pearson_r', 'n_samples']\n",
    "    print(verified_cols[display_cols].to_string(index=False))\n",
    "else:\n",
    "    print(\"  None\")\n",
    "\n",
    "print(\"\\n\\nNot verified columns (keep or investigate):\")\n",
    "not_verified_cols = results_df_sorted[results_df_sorted['verified'] == False]\n",
    "if len(not_verified_cols) > 0:\n",
    "    display_cols = ['derived_col', 'type', 'pearson_r', 'reason', 'n_samples']\n",
    "    print(not_verified_cols[display_cols].head(20).to_string(index=False))\n",
    "    if len(not_verified_cols) > 20:\n",
    "        print(f\"\\n  ... and {len(not_verified_cols) - 20} more\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "754fcaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REMOVING VERIFIED DERIVED COLUMNS\n",
      "================================================================================\n",
      "\n",
      "Columns to remove: 45\n",
      "\n",
      "Removed columns:\n",
      "   1. CO2 Per Capita\n",
      "   2. CO2 Including Land Use Change Per Capita\n",
      "   3. Coal CO2 Per Capita\n",
      "   4. Oil CO2 Per Capita\n",
      "   5. Gas CO2 Per Capita\n",
      "   6. Cement CO2 Per Capita\n",
      "   7. Flaring CO2 Per Capita\n",
      "   8. Land Use Change CO2 Per Capita\n",
      "   9. Other CO2 Per Capita\n",
      "  10. Methane Per Capita\n",
      "  11. Nitrous Oxide Per Capita\n",
      "  12. Greenhouse Gas Per Capita\n",
      "  13. Greenhouse Gas Excluding Land Use Change Per Capita\n",
      "  14. Consumption CO2 Per Capita\n",
      "  15. Energy Per Capita\n",
      "  16. CO2 Per GDP\n",
      "  17. CO2 Including Land Use Change Per GDP\n",
      "  18. Consumption CO2 Per GDP\n",
      "  19. Energy Per GDP\n",
      "  20. CO2 Per Unit Energy\n",
      "  21. CO2 Including Land Use Change Per Unit Energy\n",
      "  22. Cumulative CO2\n",
      "  23. Cumulative CO2 Including Land Use Change\n",
      "  24. Cumulative Coal CO2\n",
      "  25. Cumulative Oil CO2\n",
      "  26. Cumulative Gas CO2\n",
      "  27. Cumulative Cement CO2\n",
      "  28. Cumulative Flaring CO2\n",
      "  29. Cumulative Land Use Change CO2\n",
      "  30. Cumulative Other CO2\n",
      "  31. Share of Global CO2\n",
      "  32. Share of Global CO2 Including Land Use Change\n",
      "  33. Share of Global Coal CO2\n",
      "  34. Share of Global Oil CO2\n",
      "  35. Share of Global Gas CO2\n",
      "  36. Share of Global Cement CO2\n",
      "  37. Share of Global Flaring CO2\n",
      "  38. Share of Global Land Use Change CO2\n",
      "  39. Share of Temperature Change From Greenhouse Gas\n",
      "  40. Share of Global Other CO2\n",
      "  41. CO2 Growth Absolute\n",
      "  42. CO2 Growth Percentage\n",
      "  43. CO2 Including Land Use Change Growth Absolute\n",
      "  44. CO2 Including Land Use Change Growth Percentage\n",
      "  45. Trade CO2 Share\n",
      "\n",
      "\n",
      "Dataset Statistics:\n",
      "  Original columns: 70\n",
      "  After removal: 25\n",
      "  Columns removed: 45\n",
      "  Rows: 45,209\n",
      "\n",
      "Note: Derived columns can be recomputed from base columns after imputation.\n"
     ]
    }
   ],
   "source": [
    "# Remove verified derived columns\n",
    "verified_derived_cols = results_df[results_df['verified'] == True]['derived_col'].tolist()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"REMOVING VERIFIED DERIVED COLUMNS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nColumns to remove: {len(verified_derived_cols)}\")\n",
    "if len(verified_derived_cols) > 0:\n",
    "    print(\"\\nRemoved columns:\")\n",
    "    for i, col in enumerate(verified_derived_cols, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Create dataset without verified derived columns\n",
    "df_no_derived = df_verify.drop(columns=verified_derived_cols, errors='ignore')\n",
    "\n",
    "print(f\"\\n\\nDataset Statistics:\")\n",
    "print(f\"  Original columns: {len(df_verify.columns)}\")\n",
    "print(f\"  After removal: {len(df_no_derived.columns)}\")\n",
    "print(f\"  Columns removed: {len(df_verify.columns) - len(df_no_derived.columns)}\")\n",
    "print(f\"  Rows: {len(df_no_derived):,}\")\n",
    "\n",
    "\n",
    "print(\"\\nNote: Derived columns can be recomputed from base columns after imputation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c768d6",
   "metadata": {},
   "source": [
    "### MISSING VALUE IMPUTATION ANALYSIS\n",
    " \n",
    "### This section analyzes missing data patterns before implementing imputation\n",
    "### strategy. We'll use the cleaned dataset with renamed columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e40293c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING VALUE IMPUTATION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Dataset Shape: (45209, 25)\n",
      "Year range: 1832 to 2023\n",
      "Total missing values: 425,940\n",
      "Percentage missing: 37.69%\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned dataset with renamed columns\n",
    "df_impute = df_no_derived\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUE IMPUTATION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset Shape: {df_impute.shape}\")\n",
    "print(f\"Year range: {df_impute['Year'].min()} to {df_impute['Year'].max()}\")\n",
    "print(f\"Total missing values: {df_impute.isnull().sum().sum():,}\")\n",
    "print(f\"Percentage missing: {(df_impute.isnull().sum().sum() / (df_impute.shape[0] * df_impute.shape[1])) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67573488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING DATA PATTERN BY TIME PERIOD\n",
      "================================================================================\n",
      "1831-1850: 75.0% missing (1,259 rows)\n",
      "1850-1900: 46.9% missing (12,586 rows)\n",
      "1900-1950: 42.5% missing (12,600 rows)\n",
      "1950-1990: 30.5% missing (10,101 rows)\n",
      "1990-2010: 20.2% missing (5,093 rows)\n",
      "2010-2023: 20.1% missing (3,570 rows)\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing data by time period\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING DATA PATTERN BY TIME PERIOD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "time_periods = [\n",
    "    (1831, 1850, \"1831-1850\"),\n",
    "    (1850, 1900, \"1850-1900\"),\n",
    "    (1900, 1950, \"1900-1950\"),\n",
    "    (1950, 1990, \"1950-1990\"),\n",
    "    (1990, 2010, \"1990-2010\"),\n",
    "    (2010, 2024, \"2010-2023\")\n",
    "]\n",
    "\n",
    "for start_year, end_year, label in time_periods:\n",
    "    subset = df_impute[(df_impute['Year'] >= start_year) & (df_impute['Year'] < end_year)]\n",
    "    if len(subset) > 0:\n",
    "        missing_pct = (subset.isnull().sum().sum() / (len(subset) * len(subset.columns))) * 100\n",
    "        print(f\"{label}: {missing_pct:.1f}% missing ({len(subset):,} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df9f354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "REGIONAL AGGREGATES vs COUNTRIES\n",
      "================================================================================\n",
      "\n",
      "Countries (with ISO codes):\n",
      "  Rows: 38,838\n",
      "  Unique countries: 218\n",
      "\n",
      "Regional Aggregates (no ISO codes):\n",
      "  Rows: 6,371\n",
      "  Unique regions: 37\n",
      "\n",
      "Sample regional aggregates:\n",
      "  - Africa\n",
      "  - Africa (GCP)\n",
      "  - Asia\n",
      "  - Asia (GCP)\n",
      "  - Asia (excl. China and India)\n",
      "  - Central America (GCP)\n",
      "  - Europe\n",
      "  - Europe (GCP)\n",
      "  - Europe (excl. EU-27)\n",
      "  - Europe (excl. EU-28)\n",
      "  - European Union (27)\n",
      "  - European Union (28)\n",
      "  - High-income countries\n",
      "  - International aviation\n",
      "  - International shipping\n",
      "\n",
      "Data Completeness Comparison:\n",
      "  Countries: 35.0% missing\n",
      "  Regions: 54.2% missing\n"
     ]
    }
   ],
   "source": [
    "# Identify regional aggregates vs actual countries\n",
    "print(\"=\"*80)\n",
    "print(\"REGIONAL AGGREGATES vs COUNTRIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "countries_only = df_impute[df_impute['ISO Country Code'].notna()]\n",
    "regions = df_impute[df_impute['ISO Country Code'].isna()]\n",
    "\n",
    "print(f\"\\nCountries (with ISO codes):\")\n",
    "print(f\"  Rows: {len(countries_only):,}\")\n",
    "print(f\"  Unique countries: {countries_only['Country'].nunique()}\")\n",
    "\n",
    "print(f\"\\nRegional Aggregates (no ISO codes):\")\n",
    "print(f\"  Rows: {len(regions):,}\")\n",
    "print(f\"  Unique regions: {regions['Country'].nunique()}\")\n",
    "\n",
    "print(f\"\\nSample regional aggregates:\")\n",
    "if len(regions) > 0:\n",
    "    sample_regions = regions['Country'].unique()[:15]\n",
    "    for region in sample_regions:\n",
    "        print(f\"  - {region}\")\n",
    "\n",
    "# Show completeness comparison\n",
    "print(f\"\\nData Completeness Comparison:\")\n",
    "countries_missing_pct = (countries_only.isnull().sum().sum() / (len(countries_only) * len(countries_only.columns))) * 100\n",
    "regions_missing_pct = (regions.isnull().sum().sum() / (len(regions) * len(regions.columns))) * 100\n",
    "print(f\"  Countries: {countries_missing_pct:.1f}% missing\")\n",
    "print(f\"  Regions: {regions_missing_pct:.1f}% missing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acc2b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING VALUES BY COLUMN TYPE\n",
      "================================================================================\n",
      "\n",
      "Missing percentage for key columns:\n",
      "  Population: 13.7% (6,178 missing)\n",
      "  Gross Domestic Product: 66.5% (30,045 missing)\n",
      "  CO2 Emissions: 38.9% (17,584 missing)\n",
      "  Methane: 17.3% (7,799 missing)\n",
      "  Nitrous Oxide: 15.3% (6,929 missing)\n",
      "  Total Greenhouse Gas: 17.3% (7,799 missing)\n",
      "  Coal CO2 Emissions: 53.9% (24,374 missing)\n",
      "  Oil CO2 Emissions: 46.5% (21,021 missing)\n",
      "  Gas CO2 Emissions: 62.4% (28,225 missing)\n",
      "  Primary Energy Consumption: 77.5% (35,058 missing)\n"
     ]
    }
   ],
   "source": [
    "# Analyze missing values by column type\n",
    "print(\"=\"*80)\n",
    "print(\"MISSING VALUES BY COLUMN TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Key columns to check\n",
    "key_columns = [\n",
    "    'Population', 'Gross Domestic Product', 'CO2 Emissions', 'CO2 Per Capita',\n",
    "    'Methane', 'Nitrous Oxide', 'Total Greenhouse Gas', \n",
    "    'Coal CO2 Emissions', 'Oil CO2 Emissions', 'Gas CO2 Emissions',\n",
    "    'Primary Energy Consumption'\n",
    "]\n",
    "\n",
    "print(\"\\nMissing percentage for key columns:\")\n",
    "for col in key_columns:\n",
    "    if col in df_impute.columns:\n",
    "        missing_pct = (df_impute[col].isna().sum() / len(df_impute)) * 100\n",
    "        missing_count = df_impute[col].isna().sum()\n",
    "        print(f\"  {col}: {missing_pct:.1f}% ({missing_count:,} missing)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273372f0",
   "metadata": {},
   "source": [
    "### PHASE 2: EXCLUDE REGIONAL AGGREGATES\n",
    "\n",
    "### Filter out regional aggregates and keep only actual countries\n",
    "### (those with ISO Country Codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "54320f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXCLUDING REGIONAL AGGREGATES\n",
      "================================================================================\n",
      "\n",
      "Original dataset: 45,209 rows\n",
      "After filtering (countries only): 38,838 rows\n",
      "Removed: 6,371 rows (regional aggregates)\n",
      "\n",
      "Unique countries: 218\n",
      "Year range: 1832 to 2023\n",
      "\n",
      "Missing values:\n",
      "  Before filtering: 37.69%\n",
      "  After filtering: 34.97%\n"
     ]
    }
   ],
   "source": [
    "# Exclude regional aggregates - keep only countries with ISO codes\n",
    "df_countries = df_impute[df_impute['ISO Country Code'].notna()].copy()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"EXCLUDING REGIONAL AGGREGATES\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal dataset: {len(df_impute):,} rows\")\n",
    "print(f\"After filtering (countries only): {len(df_countries):,} rows\")\n",
    "print(f\"Removed: {len(df_impute) - len(df_countries):,} rows (regional aggregates)\")\n",
    "print(f\"\\nUnique countries: {df_countries['Country'].nunique()}\")\n",
    "print(f\"Year range: {df_countries['Year'].min()} to {df_countries['Year'].max()}\")\n",
    "\n",
    "# Show missing values after filtering\n",
    "missing_before = (df_impute.isnull().sum().sum() / (len(df_impute) * len(df_impute.columns))) * 100\n",
    "missing_after = (df_countries.isnull().sum().sum() / (len(df_countries) * len(df_countries.columns))) * 100\n",
    "print(f\"\\nMissing values:\")\n",
    "print(f\"  Before filtering: {missing_before:.2f}%\")\n",
    "print(f\"  After filtering: {missing_after:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fc8b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BASE COLUMNS (to be interpolated)\n",
      "================================================================================\n",
      "\n",
      "Total base columns: 25\n",
      "\n",
      "Base columns:\n",
      "   1. Country\n",
      "   2. Year\n",
      "   3. ISO Country Code\n",
      "   4. Population\n",
      "   5. Gross Domestic Product\n",
      "   6. CO2 Emissions\n",
      "   7. CO2 Including Land Use Change\n",
      "   8. Coal CO2 Emissions\n",
      "   9. Oil CO2 Emissions\n",
      "  10. Gas CO2 Emissions\n",
      "  11. Cement CO2 Emissions\n",
      "  12. Flaring CO2 Emissions\n",
      "  13. Land Use Change CO2\n",
      "  14. Other Industry CO2\n",
      "  15. Primary Energy Consumption\n",
      "  16. Methane\n",
      "  17. Nitrous Oxide\n",
      "  18. Total Greenhouse Gas\n",
      "  19. Total Greenhouse Gas Excluding Land Use Change\n",
      "  20. Temperature Change From CO2\n",
      "  21. Temperature Change From Methane\n",
      "  22. Temperature Change From Nitrous Oxide\n",
      "  23. Temperature Change From Greenhouse Gas\n",
      "  24. Trade CO2\n",
      "  25. Consumption CO2\n",
      "\n",
      "\n",
      "DERIVED COLUMNS (to be computed after imputation)\n",
      "================================================================================\n",
      "\n",
      "Total derived columns: 0\n",
      "\n",
      "Derived columns:\n"
     ]
    }
   ],
   "source": [
    "# Define base columns (to be interpolated directly)\n",
    "base_columns = [\n",
    "    'Country', 'Year', 'ISO Country Code',\n",
    "    'Population',\n",
    "    'Gross Domestic Product',\n",
    "    'CO2 Emissions',\n",
    "    'CO2 Including Land Use Change',\n",
    "    'Coal CO2 Emissions',\n",
    "    'Oil CO2 Emissions',\n",
    "    'Gas CO2 Emissions',\n",
    "    'Cement CO2 Emissions',\n",
    "    'Flaring CO2 Emissions',\n",
    "    'Land Use Change CO2',\n",
    "    'Other Industry CO2',\n",
    "    'Primary Energy Consumption',\n",
    "    'Methane',\n",
    "    'Nitrous Oxide',\n",
    "    'Total Greenhouse Gas',\n",
    "    'Total Greenhouse Gas Excluding Land Use Change',\n",
    "    'Temperature Change From CO2',\n",
    "    'Temperature Change From Methane',\n",
    "    'Temperature Change From Nitrous Oxide',\n",
    "    'Temperature Change From Greenhouse Gas',\n",
    "    'Trade CO2',\n",
    "    'Consumption CO2',\n",
    "]\n",
    "\n",
    "# Filter to only columns that exist in the dataframe\n",
    "base_columns = [col for col in base_columns if col in df_countries.columns]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BASE COLUMNS (to be interpolated)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal base columns: {len(base_columns)}\")\n",
    "print(\"\\nBase columns:\")\n",
    "for i, col in enumerate(base_columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Derived columns are all others (per-capita, cumulative, shares, growth metrics)\n",
    "all_columns = set(df_countries.columns)\n",
    "derived_columns = sorted(list(all_columns - set(base_columns)))\n",
    "\n",
    "print(f\"\\n\\nDERIVED COLUMNS (to be computed after imputation)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal derived columns: {len(derived_columns)}\")\n",
    "print(\"\\nDerived columns:\")\n",
    "for i, col in enumerate(derived_columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e1909e",
   "metadata": {},
   "source": [
    "\n",
    "### PHASE 3: IMPLEMENT TIME-SERIES INTERPOLATION\n",
    " \n",
    "### For each base column, interpolate missing values per country using\n",
    "### time-series methods (linear interpolation + forward/backward fill)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b96256ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Categorized Imputation...\n",
      "Log-Linear Columns: 7\n",
      "Zero-Impute Columns: 9\n",
      "Standard Linear Columns: 6\n",
      "Imputation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bg/hbf8gs7j6h1d30g9pksr5kp80000gn/T/ipykernel_40686/3491033360.py:142: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_imputed = df_countries.groupby('Country', group_keys=False).apply(impute_by_category)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ==========================================\n",
    "# 1. DEFINE THE CATEGORIES\n",
    "# ==========================================\n",
    "\n",
    "# STRATEGY A: Log-Linear Regression\n",
    "# Use for: Metrics that grow exponentially and should never be zero/negative.\n",
    "# Math: fits log(y) = mx + c\n",
    "log_linear_cols = [\n",
    "    'Population',\n",
    "    'Gross Domestic Product',\n",
    "    'Primary Energy Consumption',\n",
    "    'Total Greenhouse Gas',\n",
    "    'Total Greenhouse Gas Excluding Land Use Change',\n",
    "    'Methane',\n",
    "    'Nitrous Oxide'\n",
    "]\n",
    "\n",
    "# STRATEGY B: Zero Imputation (Hard Fill)\n",
    "# Use for: Industrial sectors that didn't exist in the past. \n",
    "# Logic: If data is missing (e.g., 1800s), assume it is 0.\n",
    "zero_impute_cols = [\n",
    "    'CO2 Emissions',             # Fossil CO2 implies industrial activity\n",
    "    'Coal CO2 Emissions',\n",
    "    'Oil CO2 Emissions',\n",
    "    'Gas CO2 Emissions',\n",
    "    'Cement CO2 Emissions',\n",
    "    'Flaring CO2 Emissions',\n",
    "    'Other Industry CO2',\n",
    "    'Trade CO2',\n",
    "    'Consumption CO2'\n",
    "]\n",
    "\n",
    "# STRATEGY C: Standard Linear Regression\n",
    "# Use for: Metrics that can be negative or have no \"zero floor\".\n",
    "# Math: fits y = mx + c (allows negatives)\n",
    "standard_linear_cols = [\n",
    "    'Temperature Change From CO2',\n",
    "    'Temperature Change From Methane',\n",
    "    'Temperature Change From Nitrous Oxide',\n",
    "    'Temperature Change From Greenhouse Gas',\n",
    "    'Land Use Change CO2',           # Can be negative (afforestation)\n",
    "    'CO2 Including Land Use Change'  # Dominated by LUC in early history\n",
    "]\n",
    "\n",
    "# ==========================================\n",
    "# 2. THE IMPUTATION FUNCTION\n",
    "# ==========================================\n",
    "\n",
    "def impute_by_category(group):\n",
    "    \"\"\"\n",
    "    Applies different imputation logic based on column category.\n",
    "    \"\"\"\n",
    "    # Sort by year to ensure timeline is correct\n",
    "    group = group.sort_values('Year').copy()\n",
    "    \n",
    "    # Get all columns in this group that need processing\n",
    "    # (Intersection of group columns and our known lists)\n",
    "    all_targets = log_linear_cols + zero_impute_cols + standard_linear_cols\n",
    "    cols_to_process = [c for c in all_targets if c in group.columns]\n",
    "\n",
    "    for col in cols_to_process:\n",
    "        # Identify missing data\n",
    "        mask_missing = group[col].isna()\n",
    "        if not mask_missing.any():\n",
    "            continue\n",
    "            \n",
    "        # ---------------------------------------------------------\n",
    "        # CATEGORY 1: ZERO IMPUTE (The User's Override)\n",
    "        # ---------------------------------------------------------\n",
    "        if col in zero_impute_cols:\n",
    "            # Simply fill missing values with 0\n",
    "            # (Assumes missing history = pre-industrial era = 0)\n",
    "            group.loc[mask_missing, col] = 0\n",
    "            continue\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # PREPARE FOR REGRESSION (Strategies A & C)\n",
    "        # ---------------------------------------------------------\n",
    "        mask_known = group[col].notna()\n",
    "        n_known = mask_known.sum()\n",
    "        \n",
    "        # Need at least 3 points to regress safely\n",
    "        if n_known < 3:\n",
    "            continue\n",
    "\n",
    "        X_known = group.loc[mask_known, 'Year'].values.reshape(-1, 1)\n",
    "        y_known = group.loc[mask_known, col].values\n",
    "        X_missing = group.loc[mask_missing, 'Year'].values.reshape(-1, 1)\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # CATEGORY 2: LOG-LINEAR\n",
    "        # ---------------------------------------------------------\n",
    "        if col in log_linear_cols:\n",
    "            # Log-Linear requires strictly positive data\n",
    "            if (y_known > 0).all():\n",
    "                # Train on Log\n",
    "                y_train = np.log(y_known)\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_known, y_train)\n",
    "                \n",
    "                # Predict and Convert Back\n",
    "                pred_log = model.predict(X_missing)\n",
    "                predictions = np.exp(pred_log)\n",
    "                \n",
    "                group.loc[mask_missing, col] = predictions\n",
    "            else:\n",
    "                # Fallback to linear if data contains zeros/negatives (rare for GDP/Pop)\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_known, y_known)\n",
    "                predictions = model.predict(X_missing)\n",
    "                predictions = np.maximum(predictions, 0) # Safety clip\n",
    "                group.loc[mask_missing, col] = predictions\n",
    "\n",
    "        # ---------------------------------------------------------\n",
    "        # CATEGORY 3: STANDARD LINEAR\n",
    "        # ---------------------------------------------------------\n",
    "        elif col in standard_linear_cols:\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_known, y_known)\n",
    "            predictions = model.predict(X_missing)\n",
    "            \n",
    "            # No clipping for Temperature/LUC (negatives allowed)\n",
    "            group.loc[mask_missing, col] = predictions\n",
    "\n",
    "    return group\n",
    "\n",
    "# ==========================================\n",
    "# 3. EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "print(\"Starting Categorized Imputation...\")\n",
    "print(f\"Log-Linear Columns: {len(log_linear_cols)}\")\n",
    "print(f\"Zero-Impute Columns: {len(zero_impute_cols)}\")\n",
    "print(f\"Standard Linear Columns: {len(standard_linear_cols)}\")\n",
    "\n",
    "# Apply the function group-by-group\n",
    "# (Assuming 'df_countries' is your main DataFrame)\n",
    "df_imputed = df_countries.groupby('Country', group_keys=False).apply(impute_by_category)\n",
    "\n",
    "print(\"Imputation Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f0be71d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Saving cleaned dataset...\")\n",
    "# df_imputed.to_csv(\"cleaned_co2_data_imputed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cafee3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (38838, 25)\n",
      "\n",
      "Column Names:\n",
      "['Country', 'Year', 'ISO Country Code', 'Population', 'Gross Domestic Product', 'Cement CO2 Emissions', 'CO2 Emissions', 'CO2 Including Land Use Change', 'Coal CO2 Emissions', 'Consumption CO2', 'Flaring CO2 Emissions', 'Gas CO2 Emissions', 'Land Use Change CO2', 'Methane', 'Nitrous Oxide', 'Oil CO2 Emissions', 'Other Industry CO2', 'Primary Energy Consumption', 'Temperature Change From Methane', 'Temperature Change From CO2', 'Temperature Change From Greenhouse Gas', 'Temperature Change From Nitrous Oxide', 'Total Greenhouse Gas', 'Total Greenhouse Gas Excluding Land Use Change', 'Trade CO2']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>ISO Country Code</th>\n",
       "      <th>Population</th>\n",
       "      <th>Gross Domestic Product</th>\n",
       "      <th>Cement CO2 Emissions</th>\n",
       "      <th>CO2 Emissions</th>\n",
       "      <th>CO2 Including Land Use Change</th>\n",
       "      <th>Coal CO2 Emissions</th>\n",
       "      <th>Consumption CO2</th>\n",
       "      <th>...</th>\n",
       "      <th>Oil CO2 Emissions</th>\n",
       "      <th>Other Industry CO2</th>\n",
       "      <th>Primary Energy Consumption</th>\n",
       "      <th>Temperature Change From Methane</th>\n",
       "      <th>Temperature Change From CO2</th>\n",
       "      <th>Temperature Change From Greenhouse Gas</th>\n",
       "      <th>Temperature Change From Nitrous Oxide</th>\n",
       "      <th>Total Greenhouse Gas</th>\n",
       "      <th>Total Greenhouse Gas Excluding Land Use Change</th>\n",
       "      <th>Trade CO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1832</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3460553.0</td>\n",
       "      <td>5.721142e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.844964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152692</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.112945</td>\n",
       "      <td>0.268513</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1833</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3476034.0</td>\n",
       "      <td>5.852474e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.852516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156830</td>\n",
       "      <td>-0.000163</td>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.166271</td>\n",
       "      <td>0.273552</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1834</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3491585.0</td>\n",
       "      <td>5.986821e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.860068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161079</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000137</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.219996</td>\n",
       "      <td>0.278687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1835</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3507205.0</td>\n",
       "      <td>6.124252e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.867620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.165444</td>\n",
       "      <td>-0.000159</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.274125</td>\n",
       "      <td>0.283917</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>1836</td>\n",
       "      <td>AFG</td>\n",
       "      <td>3522896.0</td>\n",
       "      <td>6.264838e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.875172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169928</td>\n",
       "      <td>-0.000157</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.328659</td>\n",
       "      <td>0.289246</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Country  Year ISO Country Code  Population  Gross Domestic Product  \\\n",
       "82  Afghanistan  1832              AFG   3460553.0            5.721142e+08   \n",
       "83  Afghanistan  1833              AFG   3476034.0            5.852474e+08   \n",
       "84  Afghanistan  1834              AFG   3491585.0            5.986821e+08   \n",
       "85  Afghanistan  1835              AFG   3507205.0            6.124252e+08   \n",
       "86  Afghanistan  1836              AFG   3522896.0            6.264838e+08   \n",
       "\n",
       "    Cement CO2 Emissions  CO2 Emissions  CO2 Including Land Use Change  \\\n",
       "82                   0.0            0.0                       6.844964   \n",
       "83                   0.0            0.0                       6.852516   \n",
       "84                   0.0            0.0                       6.860068   \n",
       "85                   0.0            0.0                       6.867620   \n",
       "86                   0.0            0.0                       6.875172   \n",
       "\n",
       "    Coal CO2 Emissions  Consumption CO2  ...  Oil CO2 Emissions  \\\n",
       "82                 0.0              0.0  ...                0.0   \n",
       "83                 0.0              0.0  ...                0.0   \n",
       "84                 0.0              0.0  ...                0.0   \n",
       "85                 0.0              0.0  ...                0.0   \n",
       "86                 0.0              0.0  ...                0.0   \n",
       "\n",
       "    Other Industry CO2  Primary Energy Consumption  \\\n",
       "82                 0.0                    0.152692   \n",
       "83                 0.0                    0.156830   \n",
       "84                 0.0                    0.161079   \n",
       "85                 0.0                    0.165444   \n",
       "86                 0.0                    0.169928   \n",
       "\n",
       "    Temperature Change From Methane  Temperature Change From CO2  \\\n",
       "82                        -0.000166                    -0.000141   \n",
       "83                        -0.000163                    -0.000139   \n",
       "84                        -0.000161                    -0.000137   \n",
       "85                        -0.000159                    -0.000135   \n",
       "86                        -0.000157                    -0.000133   \n",
       "\n",
       "    Temperature Change From Greenhouse Gas  \\\n",
       "82                               -0.000461   \n",
       "83                               -0.000452   \n",
       "84                               -0.000444   \n",
       "85                               -0.000435   \n",
       "86                               -0.000427   \n",
       "\n",
       "    Temperature Change From Nitrous Oxide  Total Greenhouse Gas  \\\n",
       "82                                    0.0              7.112945   \n",
       "83                                    0.0              7.166271   \n",
       "84                                    0.0              7.219996   \n",
       "85                                    0.0              7.274125   \n",
       "86                                    0.0              7.328659   \n",
       "\n",
       "    Total Greenhouse Gas Excluding Land Use Change  Trade CO2  \n",
       "82                                        0.268513        0.0  \n",
       "83                                        0.273552        0.0  \n",
       "84                                        0.278687        0.0  \n",
       "85                                        0.283917        0.0  \n",
       "86                                        0.289246        0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_imputed\n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c888d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Country Names in the Cleaned Dataset:\n",
      "Afghanistan\n",
      "Albania\n",
      "Algeria\n",
      "Andorra\n",
      "Angola\n",
      "Anguilla\n",
      "Antarctica\n",
      "Antigua and Barbuda\n",
      "Argentina\n",
      "Armenia\n",
      "Aruba\n",
      "Australia\n",
      "Austria\n",
      "Azerbaijan\n",
      "Bahamas\n",
      "Bahrain\n",
      "Bangladesh\n",
      "Barbados\n",
      "Belarus\n",
      "Belgium\n",
      "Belize\n",
      "Benin\n",
      "Bermuda\n",
      "Bhutan\n",
      "Bolivia\n",
      "Bonaire Sint Eustatius and Saba\n",
      "Bosnia and Herzegovina\n",
      "Botswana\n",
      "Brazil\n",
      "British Virgin Islands\n",
      "Brunei\n",
      "Bulgaria\n",
      "Burkina Faso\n",
      "Burundi\n",
      "Cambodia\n",
      "Cameroon\n",
      "Canada\n",
      "Cape Verde\n",
      "Central African Republic\n",
      "Chad\n",
      "Chile\n",
      "China\n",
      "Christmas Island\n",
      "Colombia\n",
      "Comoros\n",
      "Congo\n",
      "Cook Islands\n",
      "Costa Rica\n",
      "Cote d'Ivoire\n",
      "Croatia\n",
      "Cuba\n",
      "Curacao\n",
      "Cyprus\n",
      "Czechia\n",
      "Democratic Republic of Congo\n",
      "Denmark\n",
      "Djibouti\n",
      "Dominica\n",
      "Dominican Republic\n",
      "East Timor\n",
      "Ecuador\n",
      "Egypt\n",
      "El Salvador\n",
      "Equatorial Guinea\n",
      "Eritrea\n",
      "Estonia\n",
      "Eswatini\n",
      "Ethiopia\n",
      "Faroe Islands\n",
      "Fiji\n",
      "Finland\n",
      "France\n",
      "French Polynesia\n",
      "Gabon\n",
      "Gambia\n",
      "Georgia\n",
      "Germany\n",
      "Ghana\n",
      "Greece\n",
      "Greenland\n",
      "Grenada\n",
      "Guatemala\n",
      "Guinea\n",
      "Guinea-Bissau\n",
      "Guyana\n",
      "Haiti\n",
      "Honduras\n",
      "Hong Kong\n",
      "Hungary\n",
      "Iceland\n",
      "India\n",
      "Indonesia\n",
      "Iran\n",
      "Iraq\n",
      "Ireland\n",
      "Israel\n",
      "Italy\n",
      "Jamaica\n",
      "Japan\n",
      "Jordan\n",
      "Kazakhstan\n",
      "Kenya\n",
      "Kiribati\n",
      "Kuwait\n",
      "Kyrgyzstan\n",
      "Laos\n",
      "Latvia\n",
      "Lebanon\n",
      "Lesotho\n",
      "Liberia\n",
      "Libya\n",
      "Liechtenstein\n",
      "Lithuania\n",
      "Luxembourg\n",
      "Macao\n",
      "Madagascar\n",
      "Malawi\n",
      "Malaysia\n",
      "Maldives\n",
      "Mali\n",
      "Malta\n",
      "Marshall Islands\n",
      "Mauritania\n",
      "Mauritius\n",
      "Mexico\n",
      "Micronesia (country)\n",
      "Moldova\n",
      "Monaco\n",
      "Mongolia\n",
      "Montenegro\n",
      "Montserrat\n",
      "Morocco\n",
      "Mozambique\n",
      "Myanmar\n",
      "Namibia\n",
      "Nauru\n",
      "Nepal\n",
      "Netherlands\n",
      "New Caledonia\n",
      "New Zealand\n",
      "Nicaragua\n",
      "Niger\n",
      "Nigeria\n",
      "Niue\n",
      "North Korea\n",
      "North Macedonia\n",
      "Norway\n",
      "Oman\n",
      "Pakistan\n",
      "Palau\n",
      "Palestine\n",
      "Panama\n",
      "Papua New Guinea\n",
      "Paraguay\n",
      "Peru\n",
      "Philippines\n",
      "Poland\n",
      "Portugal\n",
      "Qatar\n",
      "Romania\n",
      "Russia\n",
      "Rwanda\n",
      "Saint Helena\n",
      "Saint Kitts and Nevis\n",
      "Saint Lucia\n",
      "Saint Pierre and Miquelon\n",
      "Saint Vincent and the Grenadines\n",
      "Samoa\n",
      "San Marino\n",
      "Sao Tome and Principe\n",
      "Saudi Arabia\n",
      "Senegal\n",
      "Serbia\n",
      "Seychelles\n",
      "Sierra Leone\n",
      "Singapore\n",
      "Sint Maarten (Dutch part)\n",
      "Slovakia\n",
      "Slovenia\n",
      "Solomon Islands\n",
      "Somalia\n",
      "South Africa\n",
      "South Korea\n",
      "South Sudan\n",
      "Spain\n",
      "Sri Lanka\n",
      "Sudan\n",
      "Suriname\n",
      "Sweden\n",
      "Switzerland\n",
      "Syria\n",
      "Taiwan\n",
      "Tajikistan\n",
      "Tanzania\n",
      "Thailand\n",
      "Togo\n",
      "Tonga\n",
      "Trinidad and Tobago\n",
      "Tunisia\n",
      "Turkey\n",
      "Turkmenistan\n",
      "Turks and Caicos Islands\n",
      "Tuvalu\n",
      "Uganda\n",
      "Ukraine\n",
      "United Arab Emirates\n",
      "United Kingdom\n",
      "United States\n",
      "Uruguay\n",
      "Uzbekistan\n",
      "Vanuatu\n",
      "Vatican\n",
      "Venezuela\n",
      "Vietnam\n",
      "Wallis and Futuna\n",
      "Yemen\n",
      "Zambia\n",
      "Zimbabwe\n",
      "\n",
      "Total unique countries: 218\n"
     ]
    }
   ],
   "source": [
    "# Get the unique country names from the 'Country' column\n",
    "country_names = df['Country'].unique()\n",
    "\n",
    "# Print the country names\n",
    "print(\"Unique Country Names in the Cleaned Dataset:\")\n",
    "for country in country_names:\n",
    "    print(country)\n",
    "\n",
    "print(f\"\\nTotal unique countries: {len(country_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d62ec73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 1: DEFINING COUNTRY EXISTENCE YEARS (Historical Accuracy)\n",
      "================================================================================\n",
      "\n",
      "Countries not in existence dictionary (will use first CO2 year as fallback):\n",
      "  Christmas Island: 1970\n",
      "  Monaco: 1832\n",
      "  San Marino: 1832\n",
      "  Vatican: 1832\n",
      "\n",
      "Total countries with existence years: 218\n",
      "\n",
      "Start Year Distribution:\n",
      "count     218.000000\n",
      "mean     1932.426606\n",
      "std        59.040926\n",
      "min      1832.000000\n",
      "25%      1901.250000\n",
      "50%      1960.000000\n",
      "75%      1975.000000\n",
      "max      2011.000000\n",
      "Name: START_YEAR, dtype: float64\n",
      "\n",
      "================================================================================\n",
      "AFGHANISTAN CHECK:\n",
      "  Afghanistan start year: 1919\n",
      "\n",
      "================================================================================\n",
      "SAMPLE CORRECTED START YEARS:\n",
      "================================================================================\n",
      "  Afghanistan: 1919\n",
      "  India: 1947\n",
      "  Pakistan: 1947\n",
      "  China: 1912\n",
      "  Japan: 1868\n",
      "  Germany: 1871\n",
      "  Austria: 1918\n",
      "  Hungary: 1918\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define ACTUAL country existence years based on historical formation/independence dates\n",
    "# This replaces the flawed \"first CO2 emission\" heuristic\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 1: DEFINING COUNTRY EXISTENCE YEARS (Historical Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dictionary of country formation/independence years\n",
    "# Using actual independence/formation dates for modern nation-states\n",
    "# For truly ancient nations that existed as sovereign states before 1832, we use 1832\n",
    "\n",
    "country_existence_years = {\n",
    "    # CORRECTED: Using actual independence/formation dates\n",
    "    'Afghanistan': 1919,  # Independence from British influence (Treaty of Rawalpindi)\n",
    "    'Albania': 1912,  # Independence from Ottoman Empire\n",
    "    'Algeria': 1962,  # Independence from France\n",
    "    'Andorra': 1278,  # Use 1832 (ancient nation)\n",
    "    'Angola': 1975,  # Independence from Portugal\n",
    "    'Anguilla': 1980,  # Separated from Saint Kitts and Nevis\n",
    "    'Antarctica': 1959,  # Antarctic Treaty\n",
    "    'Antigua and Barbuda': 1981,  # Independence from UK\n",
    "    'Argentina': 1816,  # Use 1832 (independence was 1816)\n",
    "    'Armenia': 1991,  # Independence from USSR\n",
    "    'Aruba': 1986,  # Separated from Netherlands Antilles\n",
    "    'Australia': 1901,  # Federation\n",
    "    'Austria': 1918,  # Republic after WWI (Habsburg Empire ended)\n",
    "    'Azerbaijan': 1991,  # Independence from USSR\n",
    "    'Bahamas': 1973,  # Independence from UK\n",
    "    'Bahrain': 1971,  # Independence from UK\n",
    "    'Bangladesh': 1971,  # Independence from Pakistan\n",
    "    'Barbados': 1966,  # Independence from UK\n",
    "    'Belarus': 1991,  # Independence from USSR\n",
    "    'Belgium': 1830,  # Use 1832\n",
    "    'Belize': 1981,  # Independence from UK\n",
    "    'Benin': 1960,  # Independence from France\n",
    "    'Bermuda': 1832,  # British territory since 1600s\n",
    "    'Bhutan': 1907,  # Monarchy established\n",
    "    'Bolivia': 1825,  # Use 1832\n",
    "    'Bonaire Sint Eustatius and Saba': 2010,  # Special municipalities\n",
    "    'Bosnia and Herzegovina': 1992,  # Independence from Yugoslavia\n",
    "    'Botswana': 1966,  # Independence from UK\n",
    "    'Brazil': 1822,  # Use 1832\n",
    "    'British Virgin Islands': 1832,  # British territory\n",
    "    'Brunei': 1984,  # Independence from UK\n",
    "    'Bulgaria': 1878,  # Independence from Ottoman Empire\n",
    "    'Burkina Faso': 1960,  # Independence from France\n",
    "    'Burundi': 1962,  # Independence from Belgium\n",
    "    'Cambodia': 1953,  # Independence from France\n",
    "    'Cameroon': 1960,  # Independence from France/UK\n",
    "    'Canada': 1867,  # Confederation\n",
    "    'Cape Verde': 1975,  # Independence from Portugal\n",
    "    'Central African Republic': 1960,  # Independence from France\n",
    "    'Chad': 1960,  # Independence from France\n",
    "    'Chile': 1818,  # Use 1832\n",
    "    'China': 1912,  # Republic of China (modern state)\n",
    "    'Colombia': 1810,  # Use 1832\n",
    "    'Comoros': 1975,  # Independence from France\n",
    "    'Congo': 1960,  # Independence from France\n",
    "    'Cook Islands': 1965,  # Self-governing\n",
    "    'Costa Rica': 1838,  # Independence\n",
    "    'Cote d\\'Ivoire': 1960,  # Independence from France\n",
    "    'Croatia': 1991,  # Independence from Yugoslavia\n",
    "    'Cuba': 1902,  # Independence from US/Spain\n",
    "    'Curacao': 2010,  # Constituent country\n",
    "    'Cyprus': 1960,  # Independence from UK\n",
    "    'Czechia': 1993,  # Split from Czechoslovakia\n",
    "    'Democratic Republic of Congo': 1960,  # Independence from Belgium\n",
    "    'Denmark': 1832,  # Ancient nation\n",
    "    'Djibouti': 1977,  # Independence from France\n",
    "    'Dominica': 1978,  # Independence from UK\n",
    "    'Dominican Republic': 1844,  # Independence\n",
    "    'East Timor': 2002,  # Independence from Indonesia\n",
    "    'Ecuador': 1830,  # Use 1832\n",
    "    'Egypt': 1922,  # Independence from UK\n",
    "    'El Salvador': 1821,  # Use 1832\n",
    "    'Equatorial Guinea': 1968,  # Independence from Spain\n",
    "    'Eritrea': 1993,  # Independence from Ethiopia\n",
    "    'Estonia': 1991,  # Re-independence from USSR\n",
    "    'Eswatini': 1968,  # Independence from UK\n",
    "    'Ethiopia': 1832,  # Ancient nation (never colonized except brief Italian occupation)\n",
    "    'Faroe Islands': 1948,  # Self-governing\n",
    "    'Fiji': 1970,  # Independence from UK\n",
    "    'Finland': 1917,  # Independence from Russia\n",
    "    'France': 1832,  # Ancient nation\n",
    "    'French Polynesia': 1946,  # Overseas territory\n",
    "    'Gabon': 1960,  # Independence from France\n",
    "    'Gambia': 1965,  # Independence from UK\n",
    "    'Georgia': 1991,  # Independence from USSR\n",
    "    'Germany': 1871,  # Unification\n",
    "    'Ghana': 1957,  # Independence from UK\n",
    "    'Greece': 1832,  # Independence from Ottoman Empire\n",
    "    'Greenland': 1979,  # Home rule\n",
    "    'Grenada': 1974,  # Independence from UK\n",
    "    'Guatemala': 1821,  # Use 1832\n",
    "    'Guinea': 1958,  # Independence from France\n",
    "    'Guinea-Bissau': 1974,  # Independence from Portugal\n",
    "    'Guyana': 1966,  # Independence from UK\n",
    "    'Haiti': 1804,  # Use 1832\n",
    "    'Honduras': 1821,  # Use 1832\n",
    "    'Hong Kong': 1842,  # British colony\n",
    "    'Hungary': 1918,  # Independence after WWI\n",
    "    'Iceland': 1944,  # Independence from Denmark\n",
    "    'India': 1947,  # Independence from UK\n",
    "    'Indonesia': 1945,  # Independence from Netherlands\n",
    "    'Iran': 1925,  # Pahlavi dynasty (modern state)\n",
    "    'Iraq': 1932,  # Independence from UK mandate\n",
    "    'Ireland': 1922,  # Independence from UK\n",
    "    'Israel': 1948,  # Independence\n",
    "    'Italy': 1861,  # Unification\n",
    "    'Jamaica': 1962,  # Independence from UK\n",
    "    'Japan': 1868,  # Meiji Restoration (modern state)\n",
    "    'Jordan': 1946,  # Independence from UK mandate\n",
    "    'Kazakhstan': 1991,  # Independence from USSR\n",
    "    'Kenya': 1963,  # Independence from UK\n",
    "    'Kiribati': 1979,  # Independence from UK\n",
    "    'Kosovo': 2008,  # Independence from Serbia\n",
    "    'Kuwait': 1961,  # Independence from UK\n",
    "    'Kyrgyzstan': 1991,  # Independence from USSR\n",
    "    'Laos': 1953,  # Independence from France\n",
    "    'Latvia': 1991,  # Re-independence from USSR\n",
    "    'Lebanon': 1943,  # Independence from France mandate\n",
    "    'Lesotho': 1966,  # Independence from UK\n",
    "    'Liberia': 1847,  # Independence\n",
    "    'Libya': 1951,  # Independence from Italy/UK/France\n",
    "    'Liechtenstein': 1806,  # Use 1832\n",
    "    'Lithuania': 1991,  # Re-independence from USSR\n",
    "    'Luxembourg': 1839,  # Independence\n",
    "    'Macao': 1832,  # Portuguese territory\n",
    "    'Madagascar': 1960,  # Independence from France\n",
    "    'Malawi': 1964,  # Independence from UK\n",
    "    'Malaysia': 1957,  # Independence from UK\n",
    "    'Maldives': 1965,  # Independence from UK\n",
    "    'Mali': 1960,  # Independence from France\n",
    "    'Malta': 1964,  # Independence from UK\n",
    "    'Marshall Islands': 1986,  # Independence from US\n",
    "    'Mauritania': 1960,  # Independence from France\n",
    "    'Mauritius': 1968,  # Independence from UK\n",
    "    'Mexico': 1821,  # Use 1832\n",
    "    'Micronesia (country)': 1986,  # Independence from US\n",
    "    'Moldova': 1991,  # Independence from USSR\n",
    "    'Mongolia': 1921,  # Independence from China\n",
    "    'Montenegro': 2006,  # Independence from Serbia\n",
    "    'Montserrat': 1832,  # British territory\n",
    "    'Morocco': 1956,  # Independence from France/Spain\n",
    "    'Mozambique': 1975,  # Independence from Portugal\n",
    "    'Myanmar': 1948,  # Independence from UK\n",
    "    'Namibia': 1990,  # Independence from South Africa\n",
    "    'Nauru': 1968,  # Independence from Australia\n",
    "    'Nepal': 1832,  # Ancient nation (never colonized)\n",
    "    'Netherlands': 1832,  # Ancient nation\n",
    "    'New Caledonia': 1946,  # Overseas territory\n",
    "    'New Zealand': 1907,  # Dominion status\n",
    "    'Nicaragua': 1821,  # Use 1832\n",
    "    'Niger': 1960,  # Independence from France\n",
    "    'Nigeria': 1960,  # Independence from UK\n",
    "    'Niue': 1974,  # Self-governing\n",
    "    'North Korea': 1948,  # Division of Korea\n",
    "    'North Macedonia': 1991,  # Independence from Yugoslavia\n",
    "    'Norway': 1905,  # Independence from Sweden\n",
    "    'Oman': 1650,  # Use 1832 (ancient sultanate)\n",
    "    'Pakistan': 1947,  # Independence from UK/India\n",
    "    'Palau': 1994,  # Independence from US\n",
    "    'Palestine': 1994,  # Palestinian Authority\n",
    "    'Panama': 1903,  # Independence from Colombia\n",
    "    'Papua New Guinea': 1975,  # Independence from Australia\n",
    "    'Paraguay': 1811,  # Use 1832\n",
    "    'Peru': 1821,  # Use 1832\n",
    "    'Philippines': 1946,  # Independence from US\n",
    "    'Poland': 1918,  # Re-independence\n",
    "    'Portugal': 1832,  # Ancient nation\n",
    "    'Qatar': 1971,  # Independence from UK\n",
    "    'Romania': 1878,  # Independence from Ottoman Empire\n",
    "    'Russia': 1832,  # Ancient nation (Russian Empire existed)\n",
    "    'Rwanda': 1962,  # Independence from Belgium\n",
    "    'Saint Helena': 1832,  # British territory\n",
    "    'Saint Kitts and Nevis': 1983,  # Independence from UK\n",
    "    'Saint Lucia': 1979,  # Independence from UK\n",
    "    'Saint Pierre and Miquelon': 1946,  # Overseas territory\n",
    "    'Saint Vincent and the Grenadines': 1979,  # Independence from UK\n",
    "    'Samoa': 1962,  # Independence from NZ\n",
    "    'Sao Tome and Principe': 1975,  # Independence from Portugal\n",
    "    'Saudi Arabia': 1932,  # Unification\n",
    "    'Senegal': 1960,  # Independence from France\n",
    "    'Serbia': 2006,  # Independence (after Montenegro split)\n",
    "    'Seychelles': 1976,  # Independence from UK\n",
    "    'Sierra Leone': 1961,  # Independence from UK\n",
    "    'Singapore': 1965,  # Independence from Malaysia\n",
    "    'Sint Maarten (Dutch part)': 2010,  # Constituent country\n",
    "    'Slovakia': 1993,  # Split from Czechoslovakia\n",
    "    'Slovenia': 1991,  # Independence from Yugoslavia\n",
    "    'Solomon Islands': 1978,  # Independence from UK\n",
    "    'Somalia': 1960,  # Independence from Italy/UK\n",
    "    'South Africa': 1910,  # Union\n",
    "    'South Korea': 1948,  # Division of Korea\n",
    "    'South Sudan': 2011,  # Independence from Sudan\n",
    "    'Spain': 1832,  # Ancient nation\n",
    "    'Sri Lanka': 1948,  # Independence from UK\n",
    "    'Sudan': 1956,  # Independence from UK/Egypt\n",
    "    'Suriname': 1975,  # Independence from Netherlands\n",
    "    'Sweden': 1832,  # Ancient nation\n",
    "    'Switzerland': 1832,  # Ancient nation\n",
    "    'Syria': 1946,  # Independence from France mandate\n",
    "    'Taiwan': 1949,  # ROC moved to Taiwan\n",
    "    'Tajikistan': 1991,  # Independence from USSR\n",
    "    'Tanzania': 1961,  # Independence from UK\n",
    "    'Thailand': 1832,  # Ancient nation (never colonized)\n",
    "    'Togo': 1960,  # Independence from France\n",
    "    'Tonga': 1970,  # Independence from UK\n",
    "    'Trinidad and Tobago': 1962,  # Independence from UK\n",
    "    'Tunisia': 1956,  # Independence from France\n",
    "    'Turkey': 1923,  # Republic founded\n",
    "    'Turkmenistan': 1991,  # Independence from USSR\n",
    "    'Turks and Caicos Islands': 1832,  # British territory\n",
    "    'Tuvalu': 1978,  # Independence from UK\n",
    "    'Uganda': 1962,  # Independence from UK\n",
    "    'Ukraine': 1991,  # Independence from USSR\n",
    "    'United Arab Emirates': 1971,  # Federation\n",
    "    'United Kingdom': 1832,  # Ancient nation\n",
    "    'United States': 1776,  # Use 1832 (independence 1776)\n",
    "    'Uruguay': 1828,  # Use 1832\n",
    "    'Uzbekistan': 1991,  # Independence from USSR\n",
    "    'Vanuatu': 1980,  # Independence from UK/France\n",
    "    'Venezuela': 1811,  # Use 1832\n",
    "    'Vietnam': 1945,  # Independence from France\n",
    "    'Wallis and Futuna': 1961,  # Overseas territory\n",
    "    'Yemen': 1990,  # Unification (North Yemen 1918, South Yemen 1967)\n",
    "    'Zambia': 1964,  # Independence from UK\n",
    "    'Zimbabwe': 1980,  # Independence from UK\n",
    "}\n",
    "\n",
    "# Ensure minimum year is 1832 (dataset start)\n",
    "for country in country_existence_years:\n",
    "    if country_existence_years[country] < 1832:\n",
    "        country_existence_years[country] = 1832\n",
    "\n",
    "# Get unique countries from the dataset\n",
    "dataset_countries = df['Country'].unique()\n",
    "\n",
    "# Find countries in dataset not in our dictionary\n",
    "missing_countries = [c for c in dataset_countries if c not in country_existence_years]\n",
    "if missing_countries:\n",
    "    print(f\"\\nCountries not in existence dictionary (will use first CO2 year as fallback):\")\n",
    "    for c in missing_countries:\n",
    "        first_co2_year = df[(df['Country'] == c) & (df['CO2 Emissions'] > 0)]['Year'].min()\n",
    "        country_existence_years[c] = first_co2_year if pd.notna(first_co2_year) else 1832\n",
    "        print(f\"  {c}: {country_existence_years[c]}\")\n",
    "\n",
    "# Create START_YEAR dataframe\n",
    "country_start_years = pd.DataFrame([\n",
    "    {'Country': country, 'START_YEAR': year} \n",
    "    for country, year in country_existence_years.items() \n",
    "    if country in dataset_countries\n",
    "])\n",
    "\n",
    "print(f\"\\nTotal countries with existence years: {len(country_start_years)}\")\n",
    "print(f\"\\nStart Year Distribution:\")\n",
    "print(country_start_years['START_YEAR'].describe())\n",
    "\n",
    "# Show Afghanistan specifically\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AFGHANISTAN CHECK:\")\n",
    "print(f\"  Afghanistan start year: {country_existence_years.get('Afghanistan', 'Not found')}\")\n",
    "\n",
    "# Show some examples of corrected dates\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE CORRECTED START YEARS:\")\n",
    "print(\"=\"*80)\n",
    "sample_countries = ['Afghanistan', 'India', 'Pakistan', 'China', 'Japan', 'Germany', 'Austria', 'Hungary']\n",
    "for country in sample_countries:\n",
    "    if country in country_existence_years:\n",
    "        print(f\"  {country}: {country_existence_years[country]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63d008bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 2: REMOVING PRE-EXISTENCE ROWS\n",
      "================================================================================\n",
      "\n",
      "Original dataset rows: 38,838\n",
      "Rows to be REMOVED (before country existence): 19,406\n",
      "Percentage of dataset to remove: 49.97%\n",
      "\n",
      "After trimming: 19,432 rows\n",
      "Rows removed: 19,406\n",
      "\n",
      "Final dataset shape: (19432, 25)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: REMOVE rows before country existence (not just zero them out)\n",
    "# Keep only data from each country's creation/existence date onwards\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 2: REMOVING PRE-EXISTENCE ROWS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Merge START_YEAR into the main dataframe\n",
    "df_with_start = df.merge(country_start_years, on='Country', how='left')\n",
    "\n",
    "print(f\"\\nOriginal dataset rows: {len(df):,}\")\n",
    "\n",
    "# Count rows that will be REMOVED\n",
    "rows_to_remove = df_with_start[df_with_start['Year'] < df_with_start['START_YEAR']]\n",
    "print(f\"Rows to be REMOVED (before country existence): {len(rows_to_remove):,}\")\n",
    "print(f\"Percentage of dataset to remove: {(len(rows_to_remove) / len(df_with_start)) * 100:.2f}%\")\n",
    "\n",
    "# Keep only rows where Year >= START_YEAR (country exists)\n",
    "df_trimmed = df_with_start[df_with_start['Year'] >= df_with_start['START_YEAR']].copy()\n",
    "\n",
    "# Remove the START_YEAR helper column\n",
    "df_trimmed = df_trimmed.drop(columns=['START_YEAR'])\n",
    "\n",
    "print(f\"\\nAfter trimming: {len(df_trimmed):,} rows\")\n",
    "print(f\"Rows removed: {len(df) - len(df_trimmed):,}\")\n",
    "print(f\"\\nFinal dataset shape: {df_trimmed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "97fbc5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 3: VALIDATION - DATA INTEGRITY AFTER ROW REMOVAL\n",
      "================================================================================\n",
      "\n",
      "1. EARLY EMITTERS - First year in trimmed dataset:\n",
      "  United States: 1832-2023 (192 rows)\n",
      "  United Kingdom: 1832-2023 (192 rows)\n",
      "  Germany: 1871-2023 (153 rows)\n",
      "  France: 1832-2023 (192 rows)\n",
      "\n",
      "2. RECENT NATIONS - Verifying correct start years:\n",
      "  South Sudan: 2011-2023 (13 rows)\n",
      "  Montenegro: 2006-2023 (18 rows)\n",
      "  Serbia: 2006-2023 (18 rows)\n",
      "  East Timor: 2002-2023 (22 rows)\n",
      "\n",
      "3. POST-SOVIET STATES (should start from 1991):\n",
      "  Ukraine: starts 1991 (33 rows)\n",
      "  Estonia: starts 1991 (33 rows)\n",
      "  Latvia: starts 1991 (33 rows)\n",
      "  Lithuania: starts 1991 (33 rows)\n",
      "  Kazakhstan: starts 1991 (33 rows)\n",
      "\n",
      "================================================================================\n",
      "SUMMARY:\n",
      "================================================================================\n",
      "Total countries: 218\n",
      "Total rows: 19,432\n",
      "Year range in dataset: 1832 to 2023\n",
      "Total CO2 Emissions: 1,696,410.98\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Validation - Verify data integrity after row removal\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 3: VALIDATION - DATA INTEGRITY AFTER ROW REMOVAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test Case 1: Check that early emitters still have data from their start year\n",
    "early_emitters = ['United States', 'United Kingdom', 'Germany', 'France']\n",
    "print(\"\\n1. EARLY EMITTERS - First year in trimmed dataset:\")\n",
    "for country in early_emitters:\n",
    "    country_data = df_trimmed[df_trimmed['Country'] == country]\n",
    "    if len(country_data) > 0:\n",
    "        first_year = country_data['Year'].min()\n",
    "        last_year = country_data['Year'].max()\n",
    "        num_rows = len(country_data)\n",
    "        print(f\"  {country}: {first_year}-{last_year} ({num_rows} rows)\")\n",
    "\n",
    "# Test Case 2: Check recent nations\n",
    "print(\"\\n2. RECENT NATIONS - Verifying correct start years:\")\n",
    "recent_nations = ['South Sudan', 'Kosovo', 'Montenegro', 'Serbia', 'East Timor']\n",
    "for country in recent_nations:\n",
    "    country_data = df_trimmed[df_trimmed['Country'] == country]\n",
    "    if len(country_data) > 0:\n",
    "        first_year = country_data['Year'].min()\n",
    "        last_year = country_data['Year'].max()\n",
    "        num_rows = len(country_data)\n",
    "        print(f\"  {country}: {first_year}-{last_year} ({num_rows} rows)\")\n",
    "\n",
    "# Test Case 3: Post-Soviet states\n",
    "print(\"\\n3. POST-SOVIET STATES (should start from 1991):\")\n",
    "post_soviet = ['Ukraine', 'Estonia', 'Latvia', 'Lithuania', 'Kazakhstan']\n",
    "for country in post_soviet:\n",
    "    country_data = df_trimmed[df_trimmed['Country'] == country]\n",
    "    if len(country_data) > 0:\n",
    "        first_year = country_data['Year'].min()\n",
    "        num_rows = len(country_data)\n",
    "        print(f\"  {country}: starts {first_year} ({num_rows} rows)\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total countries: {df_trimmed['Country'].nunique()}\")\n",
    "print(f\"Total rows: {len(df_trimmed):,}\")\n",
    "print(f\"Year range in dataset: {df_trimmed['Year'].min()} to {df_trimmed['Year'].max()}\")\n",
    "print(f\"Total CO2 Emissions: {df_trimmed['CO2 Emissions'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5faa5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4: SAVING FINAL TRIMMED DATASET\n",
      "================================================================================\n",
      "\n",
      "✓ Dataset saved as: final_trimmed_co2_data.csv\n",
      "\n",
      "Final Dataset Summary:\n",
      "  Shape: (19432, 25)\n",
      "  Countries: 218\n",
      "  Year range: 1832 to 2023\n",
      "  Total CO2 Emissions: 1,696,410.98\n",
      "\n",
      "================================================================================\n",
      "SAMPLE OF FINAL TRIMMED DATA:\n",
      "================================================================================\n",
      "        Country  Year  CO2 Emissions  Population  Gross Domestic Product\n",
      "87  Afghanistan  1919            0.0   9976355.0            4.121187e+09\n",
      "88  Afghanistan  1920            0.0  10188845.0            4.215791e+09\n",
      "89  Afghanistan  1921            0.0  10162753.0            4.312567e+09\n",
      "90  Afghanistan  1922            0.0   9893152.0            4.411565e+09\n",
      "91  Afghanistan  1923            0.0   9374030.0            4.512835e+09\n",
      "92  Afghanistan  1924            0.0   8882148.0            4.616430e+09\n",
      "93  Afghanistan  1925            0.0   8416077.0            4.722403e+09\n",
      "94  Afghanistan  1926            0.0   7974462.0            4.830808e+09\n",
      "95  Afghanistan  1927            0.0   7556019.0            4.941702e+09\n",
      "96  Afghanistan  1928            0.0   7159534.0            5.055142e+09\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Save the final trimmed dataset\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"STEP 4: SAVING FINAL TRIMMED DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save to CSV\n",
    "output_filename = 'final_trimmed_co2_data.csv'\n",
    "df_trimmed.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\n✓ Dataset saved as: {output_filename}\")\n",
    "print(f\"\\nFinal Dataset Summary:\")\n",
    "print(f\"  Shape: {df_trimmed.shape}\")\n",
    "print(f\"  Countries: {df_trimmed['Country'].nunique()}\")\n",
    "print(f\"  Year range: {df_trimmed['Year'].min()} to {df_trimmed['Year'].max()}\")\n",
    "print(f\"  Total CO2 Emissions: {df_trimmed['CO2 Emissions'].sum():,.2f}\")\n",
    "\n",
    "# Show final sample\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SAMPLE OF FINAL TRIMMED DATA:\")\n",
    "print(\"=\"*80)\n",
    "print(df_trimmed[['Country', 'Year', 'CO2 Emissions', 'Population', 'Gross Domestic Product']].head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
